/**
 ** Copyright 2016 General Electric Company
 **
 **
 ** Licensed under the Apache License, Version 2.0 (the "License");
 ** you may not use this file except in compliance with the License.
 ** You may obtain a copy of the License at
 ** 
 **     http://www.apache.org/licenses/LICENSE-2.0
 ** 
 ** Unless required by applicable law or agreed to in writing, software
 ** distributed under the License is distributed on an "AS IS" BASIS,
 ** WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 ** See the License for the specific language governing permissions and
 ** limitations under the License.
 */


package com.ge.research.semtk.belmont;

import java.util.ArrayList;
import java.util.HashMap;
import java.util.Hashtable;
import java.util.Iterator;
import java.util.UUID;

import org.json.simple.JSONArray;
import org.json.simple.JSONObject;

import com.ge.research.semtk.belmont.AutoGeneratedQueryTypes;
import com.ge.research.semtk.belmont.BelmontUtil;
import com.ge.research.semtk.belmont.Node;
import com.ge.research.semtk.belmont.NodeItem;
import com.ge.research.semtk.belmont.PropertyItem;
import com.ge.research.semtk.belmont.Returnable;
import com.ge.research.semtk.belmont.runtimeConstraints.RuntimeConstrainedItems;
import com.ge.research.semtk.belmont.runtimeConstraints.RuntimeConstrainedObject;
import com.ge.research.semtk.load.utility.UriResolver;
import com.ge.research.semtk.ontologyTools.ClassException;
import com.ge.research.semtk.ontologyTools.OntologyClass;
import com.ge.research.semtk.ontologyTools.OntologyInfo;
import com.ge.research.semtk.ontologyTools.OntologyName;
import com.ge.research.semtk.ontologyTools.OntologyPath;
import com.ge.research.semtk.ontologyTools.OntologyProperty;
import com.ge.research.semtk.ontologyTools.PathException;
import com.ge.research.semtk.sparqlX.SparqlConnection;

public class NodeGroup {
	private static final int VERSION = 7;
	// actually used to keep track of our nodes and the nomenclature in use. 
	private HashMap<String, String> sparqlNameHash = null;
	private ArrayList<Node> nodes = new ArrayList<Node>();
	private int limit = 0;
	private int offset = 0;
	private ArrayList<OrderElement> orderBy = new ArrayList<OrderElement>();

	private ArrayList<Node> orphanOnCreate = new ArrayList<Node>();
	private HashMap<String, String> prefixHash = new HashMap<String, String>();
	private int prefixNumberStart = 0;
	private SparqlConnection conn = null;
	
	public NodeGroup(){
		this.sparqlNameHash = new HashMap<String, String>();
	}
	
	public int getPrefixNumberStart(){
		return this.prefixNumberStart;
	}
	
	/**
	 * Create a NodeGroup from JSON
	 * 
	 * DANGER: no connection info, which is now required for multi-graph sparql generation
	 *         Strongly consider using SparqlGraphJson.getNodeGroup()
	 * @throws Exception 
	 */
	public static NodeGroup getInstanceFromJson(JSONObject json) throws Exception  {
		return NodeGroup.getInstanceFromJson(json, null);
	}
	
	/**
	 * Create a NodeGroup from JSON
	 * 
	 * DANGER: no connection info, which is now required for multi-graph sparql generation
	 *         Strongly consider using SparqlGraphJson.getNodeGroup()
	 * @throws Exception 
	 */
	public static NodeGroup getInstanceFromJson(JSONObject json, OntologyInfo uncompressOInfo) throws Exception {
		NodeGroup nodegroup = new NodeGroup();
		nodegroup.addJsonEncodedNodeGroup(json, uncompressOInfo);
		return nodegroup;
	}
	
	/**
	 * Create a NodeGroup from the (JSON) results of a CONSTRUCT query.
	 * @param jobj the output of a SPARQL construct query (assume key is @graph)
	 * @return a NodeGroup containing the construct query results
	 * @throws Exception 
	 * @ 
	 */
	public static NodeGroup fromConstructJSON(JSONObject jobj) throws Exception {
				
		if(jobj == null){
			throw new Exception("Cannot create NodeGroup from null JSON object");
		}		
		
		// get the contents of @graph
		JSONArray nodeArr = (JSONArray) jobj.get("@graph");  
		if(nodeArr == null){
			throw new Exception("No @graph key found when trying to create node group from construct query");
		}

		NodeGroup nodeGroup = new NodeGroup();		
		HashMap<String,Node> nodeHash = new HashMap<String,Node>(); // maps node URI to Node
		
		// first pass - gather each node's id, type, and primitive properties (but skip its properties that are node items)
		for (int i = 0; i < nodeArr.size(); i++) {
			
			JSONObject nodeJson = (JSONObject) nodeArr.get(i);	
			// e.g. sample nodeJSON:
			// {
			//	"@id":"http:\/\/research.ge.com\/print\/data#Cell_ABC",
			//	"@type":[{"@id":"http:\/\/research.ge.com\/print\/testconfig#Cell"}],  ... IN VIRTUOSO 7.2.5+, NO @id HERE
			//	"http:\/\/research.ge.com\/print\/testconfig#cellId":[{"@value":"ABC","@type":"http:\/\/www.w3.org\/2001\/XMLSchema#string"}],
			//	"http:\/\/research.ge.com\/print\/testconfig#screenPrinting":[{"@id":"http:\/\/research.ge.com\/print\/data#Prnt_ABC_2000-01-01"}],
			//	"http:\/\/research.ge.com\/print\/testconfig#sizeInches":[2]
			//	}
			
			// gather basic node info
			String instanceURI = nodeJson.get("@id").toString();  // node id
						
			// this format differs between Virtuoso 7.2 and 7.2.5.  Support both.
			String classURI;
			Object typeEntry0 = (((JSONArray)nodeJson.get("@type"))).get(0);
			if(typeEntry0 instanceof JSONObject && ((JSONObject)typeEntry0).containsKey("@id")){
				classURI = ((JSONObject)typeEntry0).get("@id").toString(); // "@type" : [ { "@id": "http://research.ge.com/energy/turbineeng/configuration#TestType"} ]  (in Virtuoso 7.2)
			}else{
				classURI = typeEntry0.toString(); // "@type" : [ "http://research.ge.com/energy/turbineeng/configuration#TestType" ] }   (in Virtuoso 7.2.5+)
			}						
			String name = (new OntologyName(classURI)).getLocalName();									
			
			// create the Node and add it to the NodeGroup
			Node node = new Node(name, null, null, classURI, nodeGroup); 
			node.setInstanceValue(instanceURI);		
			nodeHash.put(instanceURI, node); 				// add node to node hash
			nodeGroup.addOneNode(node, null, null, null);	// add node to node group
						
			ArrayList<PropertyItem> properties = new ArrayList<PropertyItem>();
			Iterator<String> keysItr = (Iterator<String>) nodeJson.keySet().iterator();
		    while(keysItr.hasNext()) {
		    			    	
		        String key = keysItr.next();
		        Object value = nodeJson.get(key);		        
		        if(key.equals("@id") || key.equals("@type")){
		        	continue;  // already got node id and type above, so skip
		        }		        
		        		        
		        // primitive properties are like this:
		        // e.g. KEY=http://research.ge.com/print/testconfig#material VALUE=[{"@value":"Red Paste","@type":"http:\/\/www.w3.org\/2001\/XMLSchema#string"} {"@value":"Blue Paste","@type":"http:\/\/www.w3.org\/2001\/XMLSchema#string"}]
		        		         
		        JSONArray valueArray = (JSONArray)value; 	// the value is an array
	        	if(!((JSONObject)((valueArray).get(0))).containsKey("@type")){  // check the first element - if no @type then this is not a primitive property   
	        		continue;  
	        	}		        
	        	
		        PropertyItem property = null;
		        for(int j = 0; j < valueArray.size(); j++){ 
		        	JSONObject valueJSONObject = (JSONObject)((valueArray).get(j));	 
		        	if(property == null){  // only create property once
		        		String relationship = key; 		// e.g. http://research.ge.com/print/testconfig#material
		        		String propertyValueType = valueJSONObject.get("@type").toString();	// e.g. http://www.w3.org/2001/XMLSchema#string
		        		String relationshipLocal = new OntologyName(relationship).getLocalName();   // e.g. pasteMaterial
		        		String propertyValueTypeLocal = new OntologyName(propertyValueType).getLocalName();	// e.g. string
		        		property = new PropertyItem(relationshipLocal, propertyValueTypeLocal, propertyValueType, relationship); 		        		
		        	}
		        	String propertyValue = valueJSONObject.get("@value").toString();  // e.g. Ce0.8Sm0.2 Oxide Paste
		        	property.addInstanceValue(propertyValue);		        
		        }	
		        property.setIsReturned(true);	// note - Javascript had this inside the for loop
		        properties.add(property);		// note - Javascript had this inside the for loop
		    }
		    node.setProperties(properties);  // add the properties to the node		    
		}
		

		// second pass - gather properties that are links to other nodes
		// this can only be done after all of the nodes are created		
		for (int i = 0; i < nodeArr.size(); i++) {
			
			JSONObject nodeJson = (JSONObject) nodeArr.get(i);	
		    
			// this is the node to link from - retrieve it from the hash
        	String fromNodeURI = nodeJson.get("@id").toString(); 
        	Node fromNode = nodeHash.get(fromNodeURI);  	        
			
			ArrayList<NodeItem> nodeItems = new ArrayList<NodeItem>();
		    Iterator<String> keysItr = (Iterator<String>) nodeJson.keySet().iterator();
		    while(keysItr.hasNext()) {
		    			    	
		        String key = keysItr.next();
		        Object value = nodeJson.get(key);		        		        
		        if(key.equals("@id") || key.equals("@type")){
		        	continue;  // already got node id and type above, so skip
		        }		        

		        // node items are in this format:
		        // e.g. KEY=http://research.ge.com/print/testconfig#screenPrinting VALUE=[{"@id":"http:\/\/research.ge.com\/print\/data#ScrnPrnt_ABC"}]        		        
		        
		        JSONArray valueArray = (JSONArray)value; 	// the value is an array
	        	if(((JSONObject)((valueArray).get(0))).containsKey("@type")){  // check the first element - if has @type then this is not a node item
	        		continue;  
	        	}
		        
		        NodeItem nodeItem = null;
		        for(int j = 0; j < valueArray.size(); j++){
		        	JSONObject valueJSONObject = ((JSONObject)(valueArray).get(j));	// the value is an array 	      		        

			        String relationship = key;  // e.g. http://research.ge.com/print/testconfig#screenPrinting
			        String relationshipLocal = (new OntologyName(relationship)).getLocalName(); // e.g. screenPrinting			        
		        	String toNodeURI = valueJSONObject.get("@id").toString(); // e.g. http://research.ge.com/print/data#ScrnPrnt_ABC
		        	String toNodeURILocal = (new OntologyName(toNodeURI)).getLocalName(); // e.g. ScrnPrnt_ABC
			        Node toNode = nodeHash.get(toNodeURI);  
			        String toNodeClassURI = toNode.getFullUriName(); // e.g. http://research.ge.com/print/testconfig#ScreenPrinting		        	
			        
		        	if(nodeItem == null){  // only create node item once
				        nodeItem = new NodeItem(relationshipLocal, (new OntologyName(toNodeClassURI)).getLocalName(), toNodeClassURI); 
				        nodeItem.setConnected(true);
			        	nodeItem.setConnectBy(relationshipLocal);
				        nodeItem.setUriConnectBy(relationship);				        
		        	}
		        	nodeItem.pushNode(toNode);  // add all instance values to it
		        }		  
				nodeItems.add(nodeItem);
		    }
		    fromNode.setNodeItems(nodeItems);	
		    
		    if(fromNode.getInstanceValue() != null){  // differs from javascript, may need to modify later
		    	fromNode.setIsReturned(true);  
		    }

		}		    		  
		
		return nodeGroup;
	}
	
	public void addOrphanedNode(Node node){
		// add to the onrphanOncreateList
		this.orphanOnCreate.add(node);
		// also, add to the list of known nodes
		this.nodes.add(node);
	}
	
	/**
	 * Use JSON fuctionality to implement deepCopy
	 * @param nodegroup
	 * @return a deep copy
	 * @throws Exception 
	 * @
	 */
	public static NodeGroup deepCopy(NodeGroup nodegroup) throws Exception  {
		NodeGroup copy = new NodeGroup();
		copy.addJsonEncodedNodeGroup(nodegroup.toJson());
		
		// connection
		SparqlConnection conn = new SparqlConnection();
		conn.fromJson(nodegroup.conn.toJson());
		copy.setSparqlConnection(conn);
		
		return copy;
	}
	
	public int getLimit() {
		return this.limit;
	}

	public void setLimit(int limit) {
		this.limit = limit;
	}
	
	public int getOffset() {
		return this.offset;
	}
	
	public void clearOrderBy() {
		this.orderBy = new ArrayList<OrderElement>();
	}
	
	public void appendOrderBy(String sparqlID) throws Exception {
		this.appendOrderBy(sparqlID, "");
	}
	
	public void appendOrderBy(OrderElement e) throws Exception {
		this.appendOrderBy(e.getSparqlID(), e.getFunc());
	}
	
	public void appendOrderBy(String sparqlID, String func) throws Exception {
		if (this.getItemBySparqlID(sparqlID) == null) {
			throw new Exception(String.format("SparqlID can't be found in nodegroup: '%s'", sparqlID));
			
		} else if (this.orderBy.contains(sparqlID)) {
			throw new Exception(String.format("SparqlID can't be added to ORDER BY twice: '%s'", sparqlID));

		} else {
			this.orderBy.add(new OrderElement(sparqlID, func));
		}
	}
	
	public void removeInvalidOrderBy() {
		ArrayList<OrderElement> keep = new ArrayList<OrderElement>();
		
		for (OrderElement e : this.orderBy) {
			if (this.getItemBySparqlID(e.getSparqlID()) != null) {
				keep.add(e);
			}
		}
		
		this.orderBy = keep;
	}
	
	public void validateOrderBy() throws Exception {		

		for (OrderElement e : this.orderBy) {
			if (this.getItemBySparqlID(e.getSparqlID()) == null) {
				throw new Exception(String.format("Invalid SparqlID in ORDER BY : '%s'", e.getSparqlID()));
			}
		}
	}
	
	/**
	 * Set orderBy to every returned item.
	 * (To ensure a deterministic return order for OFFSET)
	 * @throws Exception
	 */
	public void orderByAll() throws Exception {
		this.clearOrderBy();
		for (Returnable r : this.getReturnedItems()) {
			this.appendOrderBy(r.getSparqlID());
		}
	}

	public void setOffset(int offset) {
		this.offset = offset;
	}
	
	private String getPrefixedUri(String originalUri) throws Exception {
		String retval = "";
		if(originalUri == null ){
			throw new Exception("prefixed URI " + originalUri + " does not seem to contain a proper prefix.");
		}
		else if(originalUri.indexOf("#") == -1 ){
			return originalUri;
		}
		else{
			// get the chunks and build the prefixed string.
			String[] chunks = originalUri.split("#");
			String pre = this.prefixHash.get(chunks[0]);
			
			if(chunks.length > 1 ){
				retval = pre + ":" + chunks[1];
			}
			else{
				retval = pre + ":";
			}
		}
		
		return retval;
	}
	
	private String legalizePrefixName(String suggestion) {
		// replace illegal characters with "_"
		
		String ret = suggestion.replaceAll("[^A-Za-z_0-9]", "_");
		if (! Character.isLetter(ret.charAt(0))) {
			ret = "a" + ret;
		}
		
		return ret;
	}
	
	public void addToPrefixHash(String prefixedUri){
		// from the incoming string, remove the local fragment and then try to add the rest to the prefix hash.
		if(prefixedUri == null){ return; }
		if(!prefixedUri.contains("#")){ return; }
		
		String[] chunks = prefixedUri.split("#");
		
		// found a new prefix
		if(!this.prefixHash.containsKey(chunks[0])) {
			// create a new prefix name
			String [] fragments = chunks[0].split("/");
			String newPrefixName = fragments[fragments.length - 1];
			
			// make sure prefix starts with a number
			newPrefixName = this.legalizePrefixName(newPrefixName);
			
			// make sure new prefix name is unique
			if (this.prefixHash.containsValue(newPrefixName)) {
				int i=0;
				while (this.prefixHash.containsValue(newPrefixName + "_" + i)) {
					i++;
				}
				newPrefixName = newPrefixName + "_" + i;
			}
			
			//String newPrefixName = "pre_" + this.prefixNumberStart;
			this.prefixNumberStart += 1;  // also obsolete I think
			
			this.prefixHash.put(chunks[0], newPrefixName);
			
			//System.err.println("adding prefix: " + newPrefixName + " with key " + chunks[0] + " from input " + prefixedUri);
		}
	}
	
	public void rebuildPrefixHash(HashMap<String, String> startingMap){
		
		this.prefixHash = new HashMap<String, String>();		// x out the old map.
		
		this.prefixHash = startingMap;							// replace it.
		this.prefixNumberStart = startingMap.size();
		addAllToPrefixHash();
		
	}
	
	private void addAllToPrefixHash(){

		this.addToPrefixHash(UriResolver.DEFAULT_URI_PREFIX);   // make sure to force the inclusion of the old ones.
		this.addToPrefixHash("http://www.w3.org/2001/XMLSchema#");
		
		for(Node n : this.nodes){

			if(n.getInstanceValue() != null && n.getInstanceValue().contains("#")){
				this.addToPrefixHash(n.getInstanceValue());
			}			
			// add the prefix for each node.
			this.addToPrefixHash(n.getFullUriName());
			// add the URIs for the properties as well:
			for(PropertyItem pi : n.getPropertyItems()){
				this.addToPrefixHash(pi.getUriRelationship());
			}
			// add the URIs for the node items
			for(NodeItem ni : n.getNodeItemList()){
				this.addToPrefixHash(ni.getUriConnectBy());
			}
		}

	}
	
	public HashMap<String, String> getPrefixHash(){
		
		if(this.prefixHash != null && this.prefixHash.size() != 0){
			return this.prefixHash;
		}
		else{
			this.buildPrefixHash();		// create something to send.
			return this.prefixHash;
		}
		
	}
	
	public void buildPrefixHash(){
		
		if(this.prefixHash.size() != 0){
			return;
		}
		else{
		// if possible, add the default prefix and user prefix:
			addAllToPrefixHash();
		}
	}
	
	public String generateSparqlPrefix(){
		StringBuilder retval = new StringBuilder();
		
		// check that it is built!
		if(this.prefixHash.size() == 0) { this.buildPrefixHash(); }
		
		for(String k : this.prefixHash.keySet()){
			retval.append("prefix ").append(this.prefixHash.get(k)).append(":<").append(k).append("#>\n");
		}
				
		return(retval.toString());
	}
	
	public static String tabIndent(String tab) {
		return tab.concat("\t");
	}
	
	public static String tabOutdent(String tab) {
		return tab.substring(0, tab.length()-1);
	}
	public void addJsonEncodedNodeGroup(JSONObject jobj) throws Exception {
		this.addJsonEncodedNodeGroup(jobj, null);
	}
	
	public void addJsonEncodedNodeGroup(JSONObject jobj, OntologyInfo uncompressOInfo) throws Exception {
		HashMap<String, String> changedHash = new HashMap<String, String>();
		this.resolveSparqlIdCollisions(jobj, changedHash);
		int version = Integer.parseInt(jobj.get("version").toString());
		if (version > NodeGroup.VERSION) {
			throw new Exception (String.format("This software reads NodeGroups through version %d.  Can't read version %d.", NodeGroup.VERSION, version));
		}
		
		if (jobj.containsKey("limit")) {
			this.setLimit(Integer.parseInt(jobj.get("limit").toString()));
		}
		
		if (jobj.containsKey("offset")) {
			this.setOffset(Integer.parseInt(jobj.get("offset").toString()));
		}
		
		// attempt to add the nodes, using "changedHash" as a guide for IDs.Integer.parseInt
		this.addJson((JSONArray) jobj.get("sNodeList"), uncompressOInfo); 
		
		if (jobj.containsKey("orderBy")) {
			JSONArray oList = (JSONArray) jobj.get("orderBy");
			for (int i=0; i < oList.size(); i++) {
				JSONObject j = (JSONObject) oList.get(i);
				OrderElement e = new OrderElement(j);
				this.appendOrderBy(e); 
			}
		}
		
		this.validateOrderBy();
	}
	
	public void addJson(JSONArray nodeArr) throws Exception  {
		this.addJson(nodeArr, null);
	}
	
	/**
	 * Add json to a nodegroup
	 * @param nodeArr
	 * @param uncompressOInfo If non-null, use this to uncompress any Node properties
	 * @throws Exception 
	 * @
	 */
	public void addJson(JSONArray nodeArr, OntologyInfo uncompressOInfo) throws Exception  {
		for (int j = 0; j < nodeArr.size(); ++j) {
			JSONObject nodeJson = (JSONObject) nodeArr.get(j);
			
			Node curr  = new Node(nodeJson, this, uncompressOInfo);
			Node check = this.getNodeBySparqlID(curr.getSparqlID());
			
			// create nodes we have never seen
			if(check == null){
				this.addOneNode(curr, null, null, null);
			}
			// modify the existing node:
			else{

				// if the node is in both the nodesList and orphan list, modify it. 
				check = null;
				for(Node nd : this.orphanOnCreate){
					if(curr.sparqlID.equals(nd.sparqlID)){						
						check = nd;
						break;
					}
				}
				if(check != null){
					// remove from the orphan list. we do not want to mod this node more than once. 
				//	this.orphanOnCreate.remove(check);
					check.updateFromJson(nodeJson);
				}
				else{
					throw new Exception( "--uncreated node referenced: " + curr.sparqlID );
				}
					
			}
			
		}
		this.orphanOnCreate.clear();
	}
	
	public ArrayList<Node> getNodeList(){
		return this.nodes;
	}
	
	public void addOneNode(Node curr, Node existingNode, String linkFromNewUri, String linkToNewUri) throws Exception  {


		// reserve the node SparqlID
		this.reserveNodeSparqlIDs(curr);
		
		// add the node to the nodegroup control structure..
		this.nodes.add(curr);
		// set up the connection info so this node participates in the graph
		if(linkFromNewUri != null && linkFromNewUri != ""){
			curr.setConnection(existingNode, linkFromNewUri);
		}
		else if(linkToNewUri != null && linkToNewUri != ""){
			existingNode.setConnection(curr, linkToNewUri);
		}
		else{
			//no op
		}
		
	}

	private void reserveNodeSparqlIDs(Node curr) {
		String ID = curr.getSparqlID();
		if(this.sparqlNameHash.containsKey(ID)){	// this name was already used. 
			ID = BelmontUtil.generateSparqlID(ID, this.sparqlNameHash);
			curr.setSparqlID(ID);	// update it. 
		}
		this.reserveSparqlID(ID);	// actually hold the name now. 
		
		// check the properties...
		ArrayList<PropertyItem> props = curr.getReturnedPropertyItems();
		for(int i = 0; i < props.size(); i += 1){
			String pID = props.get(i).getSparqlID();
			if(this.sparqlNameHash.containsKey(pID)){
				pID = BelmontUtil.generateSparqlID(pID, this.sparqlNameHash);
				props.get(i).setSparqlID(pID);
			}
			this.reserveSparqlID(pID);
		}
		
	}

	public void reserveSparqlID(String id) {
		if (id != null && id.length() > 0) {
			this.sparqlNameHash.put(id, "1");
		}
	}

	public void freeSparqlID(String id) {
		// alert("retiring " + id);
		if (id != null && id.length() > 0) {
			this.sparqlNameHash.remove(id);
		}
	}

	private JSONObject resolveSparqlIdCollisions(JSONObject jobj, HashMap<String, String> changedHash) {
		// loop through a json object and resolve any SparqlID name collisions
		// with this node group.
		JSONObject retval = jobj;
		
		if(this.sparqlNameHash.isEmpty()){	// nothing to do.
			return retval;
		}
		
		// set up a temp hashMap to store the values. 
		HashMap<String, String> tempHash = new HashMap<String, String>();
		tempHash.putAll(this.sparqlNameHash);
		
		
		JSONArray nodeArr = (JSONArray)jobj.get("sNodeList");
		// loop through the nodes in the JSONArray
		for(int k = 0; k < nodeArr.size(); k += 1){
			JSONObject jnode = (JSONObject) nodeArr.get(k);
			
			jnode = BelmontUtil.updateSparqlIdsForJSON(jnode, "SparqlID", changedHash, tempHash);
			
			// iterate over property objects
			JSONArray propArr = (JSONArray) jnode.get("propList");
			
			for (int j = 0; j < propArr.size(); ++j) {
				JSONObject prop = (JSONObject) propArr.get(j);
				prop = BelmontUtil.updateSparqlIdsForJSON(prop, "SparqlID", changedHash, tempHash);
			}
			
			// and the node list			
			JSONArray nodeItemArr = (JSONArray) jnode.get("nodeList");
			
			for (int j = 0; j < nodeItemArr.size(); ++j) {
				JSONObject node = (JSONObject) nodeItemArr.get(j);
				JSONArray nodeConnections = (JSONArray)node.get("SnodeSparqlIDs");
				for(int m = 0; m < nodeConnections.size(); m += 1){
					// this should update the values we care about
					JSONArray nodeInst = (JSONArray)node.get("SnodeSparqlIDs");
					nodeInst = BelmontUtil.updateSparqlIdsForJSON(nodeConnections, m, changedHash, tempHash);
				}
			}
		}
		
		return retval;
	}
	
	/**
	 * 
	 * @param uri
	 * @return ArrayList of Nodes which are of class uri
	 */
	public ArrayList<Node> getNodesByURI(String uri) {
		// get all nodes with the given uri
		ArrayList<Node> ret = new ArrayList<Node>();

		for (int i = 0; i < this.nodes.size(); i++) {
			if (this.nodes.get(i).getUri().equals(uri)) {
				ret.add(this.nodes.get(i));
			}
		}
		return ret;
	}
	
	/**
	 * 
	 * @param uri
	 * @param oInfo
	 * @return ArrayList of Nodes which are of class uri or any of its subclasses
	 */
	public ArrayList<Node> getNodesBySuperclassURI(String uri, OntologyInfo oInfo) {
		// get all nodes with the given uri
		ArrayList<Node> ret = new ArrayList<Node>();

		// get all subclasses
		ArrayList<String> classes = new ArrayList<String>();
		classes.add(uri);
		classes.addAll(oInfo.getSubclassNames(uri));
		
		// for each class / sub-class
		for (int i=0; i < classes.size(); i++) {
			// get all nodes
			ArrayList<Node> c = this.getNodesByURI(classes.get(i));
			// push node if it isn't already in ret
			for (int j=0; j < c.size(); j++) {
				if (ret.indexOf(c.get(j)) == -1) {
					ret.add(c.get(j));
				}
			}
		}
		
		return ret;
	}
	
	public Node getNodeBySparqlID(String currId) {
		// look up a node by ID and return it. 
		Node retval = null;
		for(int i = 0; i < nodes.size(); i += 1){
			// can we find it by name?
			if(this.nodes.get(i).getSparqlID().equals(currId)){   // this was "==" but that failed in some cases...
				retval = this.nodes.get(i);
				break;
			}
		}
		return retval;
	}
	
	public PropertyItem getPropertyItemBySparqlID(String currId){
		// finds the given propertyItem by assigned sparql ID.
		// if no matches are found, it returns a null... 
				
		PropertyItem retval = null;
		
		for(Node nc : this.nodes){
			PropertyItem candidate = nc.getPropertyItemBySparqlID(currId);
			if(candidate != null){
				retval = candidate;
				break;			// always in the last place we look.
			}
		}
		// return it. 
		return retval;
	}

	/**
	 * Get all returnable items in query "order"
	 * @return
	 */
	private ArrayList<Returnable> getReturnedItems() {
		ArrayList<Returnable> ret = new ArrayList<Returnable>();
		
		for(Node n : this.getOrderedNodeList()) {
			// check if node URI is returned
			if (n.getIsReturned()) {
				ret.add(n);
			}
			
			ret.addAll(n.getReturnedPropertyItems());
		}
		return ret;
	}
	
	/**
	 * Find Node or PropertyItem with sparqlID==id anywhere in nodegroup, otherwise null
	 * @param id
	 * @return
	 */
	private Returnable getItemBySparqlID(String id) {
        for (Node n : this.nodes) {
            if (n.getSparqlID().equals(id)) {
                return n;
            }
            
            Returnable item = n.getPropertyItemBySparqlID(id);
            if (item != null) {
                return item;
            }
        }
		return null;
    }
	
	public String generateSparql(AutoGeneratedQueryTypes qt, Boolean allPropertiesOptional, Integer limitOverride, Returnable targetObj) throws Exception {
		return this.generateSparql(qt, allPropertiesOptional, limitOverride, targetObj, false);
	}

	public String generateSparql(AutoGeneratedQueryTypes qt, Boolean allPropertiesOptional, Integer limitOverride, Returnable targetObj, Boolean keepTargetConstraints) throws Exception{
		//
		// queryType:
		//     QUERY_DISTINCT - select distinct.   Use of targetObj is undefined.
		//     QUERY_CONSTRAINT - select distinct values for a specific node or prop item (targetObj) after removing any existing constraints
		//     QUERY_COUNT - count results.  If targetObj the use that as the only object of "select distinct".  
		//
		// limitOverride - if > -1, then override this.limit     DEPRECATED
		//
		// targetObj - if not (null/undefined/0/false/'') then it should be a SemanticNode or a PropertyItem
		//    QUERY_CONSTRAINT - must be set.   Return all legal values for this.   Remove constraints.
        //    QUERY_COUNT - if set, count results of entire query but only this distinct return value
		//
		// keepTargetConstraints - keep constraints on the target object 
		//
		// Error handling: For each error, inserts a comment at the beginning.
		//    #Error: explanation
		
		this.buildPrefixHash();
		
		String retval = "";
		String tab = tabIndent("");
		
		if (nodes.size() == 0) {
			return retval;
		}
		
		ArrayList<Node> orderedNodes = this.getOrderedNodeList();
		StringBuilder sparql = new StringBuilder();
		sparql.append(this.generateSparqlPrefix());
		
		if (qt.equals(AutoGeneratedQueryTypes.QUERY_COUNT)) {
			sparql.append("SELECT (COUNT(*) as ?count) { \n");
		}
		
		sparql.append("select distinct");
		int lastLen = sparql.length();
		
		if (targetObj != null) {
			// QUERY_CONSTRAINT or QUERY_COUNT or anything that set targetObj:  simple
			// only the targetObj is returned
			sparql.append(" ").append(targetObj.getSparqlID());
		}
		else {
			ArrayList<Returnable> returns = this.getReturnedItems();
			for (Returnable r : returns) {
				String id = r.getSparqlID();
				if (id.isEmpty()) {
					if (r instanceof PropertyItem) {
						throw new Exception("Trying to return a property whose sparqlID is not set: " + ((PropertyItem) r).getKeyName());
					} else {
						throw new Exception("Trying to return an node URI whose sparqlID is not set: " + ((Node) r).getUri(true));
					}
				}
				sparql.append(" ").append(id);
			}
		}
		
		// if there are no return values, it is an error. Prepend "#Error" to
		// the SPARQL
		if (sparql.length() == lastLen) {
			throw new NoValidSparqlException("No values selected to return");
		}
		
		sparql.append(this.generateSparqlFromClause(tab));
		
		sparql.append(" where {\n");
		
		ArrayList<Node> doneNodes = new ArrayList<Node>();
		Node headNode = this.getNextHeadNode(doneNodes);
		while (headNode != null) {
		
			sparql.append(this.generateSparqlSubgraphClauses(	qt, 
																headNode, 
																null, null,   // skip nodeItem.  Null means do them all.
																keepTargetConstraints ? null : targetObj, 
																doneNodes, 
																tab));
			headNode = this.getNextHeadNode(doneNodes);
		}
		
		sparql.append("}\n");
		
		if (qt.equals(AutoGeneratedQueryTypes.QUERY_CONSTRAINT)) {
			// do nothing - may change in future
			// sparql += "ORDER BY " + targetObj.SparqlID + " ";
		}
		
		sparql.append(this.generateOrderByClause());
		sparql.append(this.generateLimitClause(limitOverride));
		sparql.append(this.generateOffsetClause());
		
		if (qt.equals(AutoGeneratedQueryTypes.QUERY_COUNT)) {
			sparql.append("\n}");
		}
		
		//retval = BelmontUtil.prefixQuery(sparql.toString());
		retval = sparql.toString();
		
		return retval;
	}
	
	private String generateOffsetClause() {
		if (this.offset != 0) {
			return " OFFSET " + String.valueOf(this.offset) + "\n";
		} else {
			return "";
		}
	}
	
	private String generateOrderByClause() throws Exception {
		this.validateOrderBy();
		
		if (this.orderBy.size() > 0) {
			StringBuffer ret = new StringBuffer();
			ret.append("ORDER BY");
			for (OrderElement e : this.orderBy) {
				ret.append(" ");
				ret.append(e.toSparql());
			}
			return ret.toString();
		} else {
			return "";
		}
	}
	
	/**
     *  limitOverride If non-null then override this.limit  DEPRECATED
     */
	private String generateLimitClause(Integer limitOverride) {
        int limit = (limitOverride != null && limitOverride > -1) ? limitOverride : this.limit;
        if (limit > 0) {
			return " LIMIT " + String.valueOf(limit); 
		} 
        else 
		{
            return "";
    	}
    }

	/**
	 * Very simple FROM clause logic
	 * Generates FROM clause if this.conn has
	 *     - exactly 1 serverURL
	 *     - more than one datasets (graphs)
	 */
	private String generateSparqlFromClause(String tab) {
		
		// do nothing if no conn
		if (this.conn == null) return "";
		
		// multiple ServerURLs is not implemented
		if (! this.conn.isSingleDataServerURL() ) {
			throw new Error("SPARQL generation across multiple data servers is not yet supported.");
		}
		
		// get datasets for first model server.  All others must be equal
		ArrayList<String> datasets = this.conn.getDataDatasetsForServer(this.conn.getDataInterface(0).getServerAndPort());
		
		if (datasets.size() < 2) return "";
		
		StringBuilder sparql = new StringBuilder().append("\n");
		// multiple datasets: generate FROM clause
		tab = tabIndent(tab);
		for (int i=0; i < datasets.size(); i++) {
			sparql.append(tab + "FROM <" + datasets.get(i) + ">\n");
		}
		tab = tabOutdent(tab);
		
		return sparql.toString();
	}
	
	public String generateSparqlConstruct() throws Exception {
	
		this.buildPrefixHash();
		
		String tab = tabIndent("");
		StringBuilder sparql = new StringBuilder();
		sparql.append(this.generateSparqlPrefix());
		sparql.append("construct {\n");
		
		AutoGeneratedQueryTypes queryType = AutoGeneratedQueryTypes.QUERY_CONSTRUCT;
		
		ArrayList<Node> doneNodes  = new ArrayList<Node>();
		Node headNode = this.getNextHeadNode(doneNodes);

		while (headNode != null) {
			
			sparql.append(this.generateSparqlSubgraphClauses(	queryType, 
																headNode, 
																null, null,    // skip nodeItem.  Null means do them all.
																null,    // no targetObj
																doneNodes, 
																tab));
			headNode = this.getNextHeadNode(doneNodes);
		}
		
		sparql.append("\n}");
		
		sparql.append(this.generateSparqlFromClause(""));
		
		// jm: borrowed from "GenerateSparql"
		sparql.append("\nwhere {\n");
		
		queryType = AutoGeneratedQueryTypes.QUERY_CONSTRUCT;
		doneNodes = new ArrayList<Node>();
		headNode = this.getNextHeadNode(doneNodes);
		while (headNode != null) {
		
			sparql.append(this.generateSparqlSubgraphClauses(	queryType, 
																headNode, 
																null, null,   // skip nodeItem.  Null means do them all.
																null,    // no targetObj
																doneNodes, 
																tab));
			headNode = this.getNextHeadNode(doneNodes);
		}
		
		sparql.append("}\n");
		
		return sparql.toString();
	}
	
	public String generateSparqlAsk() throws Exception {
		
		this.buildPrefixHash();
		
		// generate a sparql ask statement
		String footer = "";
		String tab = tabIndent("");
		
		ArrayList<Node> doneNodes = new ArrayList<Node>();
		
		Node headNode = this.getNextHeadNode(doneNodes);
		while (headNode != null) {
			footer += this.generateSparqlSubgraphClauses(AutoGeneratedQueryTypes.QUERY_CONSTRUCT_WHERE, headNode, null, null, null, doneNodes, tab);
			headNode = this.getNextHeadNode(doneNodes);
		}
		
		
		String retval = this.generateSparqlPrefix() + "ask  " + generateSparqlFromClause(tab) +   "\n{\n" + footer + "\n}";
 
		return retval;
	}
	
	private String generateSparqlSubgraphClauses(AutoGeneratedQueryTypes queryType, Node snode, NodeItem skipNodeItem, Node skipNodeTarget, Returnable targetObj, ArrayList<Node> doneNodes, String tab) throws Exception  {
		StringBuilder sparql = new StringBuilder();
		
		// check to see if this node has already been processed. 
		if(doneNodes.contains(snode)){
			// nothing to do.
			return sparql.toString();
		}
		else{
			doneNodes.add(snode);
		}
		
		// get the type information included in the query result. only valid on the CONTRUCT query
		if(queryType == AutoGeneratedQueryTypes.QUERY_CONSTRUCT || queryType == AutoGeneratedQueryTypes.QUERY_CONSTRUCT_WHERE){
			sparql.append(tab + snode.getSparqlID() + " a " + snode.getSparqlID() + "_type .\n");
		}
		
		
		// added for deletions
		else if (queryType == AutoGeneratedQueryTypes.QUERY_DELETE_WHERE && snode.getDeletionMode() != NodeDeletionTypes.NO_DELETE){
			sparql.append(this.generateNodeDeletionSparql(snode, true));
		}
		
		// This is the type-constraining statement for any type that needs
		// NOTE: this is at the top due to a Virtuoso bug
		sparql.append(this.generateSparqlTypeClause(snode, tab));
		//       If the first prop is optional and nothing matches then the whole query fails.
				
		// PropItems: generate sparql for property and constraints
		// for(PropertyItem prop : snode.getReturnedPropertyItems()){
		for(PropertyItem prop : snode.getPropsForSparql(targetObj, queryType)){	
			// check for being optional...
			if(prop.getIsOptional() && queryType != AutoGeneratedQueryTypes.QUERY_CONSTRUCT){
				sparql.append(tab + "optional{\n");
				tab = tabIndent(tab);
			}
			
			// SPARQL for basic prop
//			sparql.append(tab + snode.getSparqlID() + " <" + prop.getUriRelationship() + "> " + prop.getSparqlID() +  " .\n");
			sparql.append(tab + snode.getSparqlID() + " " + this.getPrefixedUri(prop.getUriRelationship()) + " " + prop.getSparqlID() +  " .\n");
		
			// add in attribute range constraint if there is one 
			if(prop.getConstraints() != null && prop.getConstraints() != ""){
				// add unless this is a CONSTRAINT query on targetObj
				if((queryType != AutoGeneratedQueryTypes.QUERY_CONSTRUCT) && (queryType != AutoGeneratedQueryTypes.QUERY_CONSTRAINT || targetObj == null || prop.getSparqlID() != targetObj.getSparqlID())){
					if(prop.getConstraints() != null && !prop.getConstraints().equalsIgnoreCase("")){
						tab = tabIndent(tab);
						sparql.append("\t" + prop.getConstraints() + " .\n");
						tab = tabOutdent(tab);
					}
				}
			}
			
			// close optional block.
			if(prop.getIsOptional() && queryType != AutoGeneratedQueryTypes.QUERY_CONSTRUCT){
				sparql.append(tab + "} \n");
			}
		}
		
		// add value constraints...
		String constraintStr = snode.getValueConstraintStr();
		if(constraintStr != null && ! constraintStr.isEmpty()) {
			// add unless this is a constraint query on the target object
			if((queryType != AutoGeneratedQueryTypes.QUERY_CONSTRUCT) && (queryType != AutoGeneratedQueryTypes.QUERY_CONSTRAINT || snode != targetObj)){
				sparql.append(tab + constraintStr + ". \n");
			}
		}

		// recursive process of NodeItem subtree  
		for(NodeItem nItem : snode.getNodeItemList()) {
			
			// each nItem might point to multiple children
			for(Node targetNode : nItem.getNodeList()) {
				

				if (nItem != skipNodeItem || targetNode != skipNodeTarget) {
					
					// open optional block
					if(nItem.getSNodeOptional(targetNode) == NodeItem.OPTIONAL_TRUE && nItem.getNodeList().size() > 0 && queryType != AutoGeneratedQueryTypes.QUERY_CONSTRUCT){
						sparql.append(tab + "optional {\n");
						tab = tabIndent(tab);
					}
					
					sparql.append("\n");
					
					// node connection, then recursive call
					// sparql.append(tab + snode.getSparqlID() + " <" + nItem.getUriConnectBy() + "> " + targetNode.getSparqlID() + " .\n");
					sparql.append(tab + snode.getSparqlID() + " " + this.getPrefixedUri(nItem.getUriConnectBy()) + " " + targetNode.getSparqlID() + " .\n");
					tab = tabIndent(tab);
					
					// RECURSION
					sparql.append(this.generateSparqlSubgraphClauses(queryType, targetNode, nItem, targetNode, targetObj, doneNodes, tab));
					tab = tabOutdent(tab);
					
					// close optional block
					if(nItem.getSNodeOptional(targetNode) == NodeItem.OPTIONAL_TRUE && nItem.getNodeList().size() > 0 && queryType != AutoGeneratedQueryTypes.QUERY_CONSTRUCT){
						tab = tabOutdent(tab);
						sparql.append(tab + "}\n");
					}
				}
			}
		}
		
	
		// Recursively process incoming nItems
		for(NodeItem nItem : this.getConnectingNodeItems(snode)) {   

			if (nItem != skipNodeItem || snode != skipNodeTarget) {
			
				// open optional
				if (nItem.getSNodeOptional(snode) == NodeItem.OPTIONAL_REVERSE && nItem.getNodeList().size() > 0  && queryType != AutoGeneratedQueryTypes.QUERY_CONSTRUCT) {
					sparql.append(tab + "optional {\n");
					tab = tabIndent(tab);
				}
				
				Node incomingSNode = this.getNodeItemParentSNode(nItem); 
				
				// the incoming connection
				if (incomingSNode != null) {
					sparql.append("\n");
					//sparql.append(tab + incomingSNode.getSparqlID() + " <" + nItem.getUriConnectBy() + "> " + snode.getSparqlID() + " .\n");
					sparql.append(tab + incomingSNode.getSparqlID() + " " + this.getPrefixedUri(nItem.getUriConnectBy()) + " " + snode.getSparqlID() + " .\n");
					tab = tabIndent(tab);
				}
				
				// RECURSION
				sparql.append(this.generateSparqlSubgraphClauses(queryType, incomingSNode, nItem, snode, targetObj, doneNodes, tab));
				tab = tabOutdent(tab);
				
				// close optional
				if (nItem.getSNodeOptional(snode) == NodeItem.OPTIONAL_REVERSE && queryType != AutoGeneratedQueryTypes.QUERY_CONSTRUCT) {
					tab = tabOutdent(tab);
					sparql.append(tab + "}\n");
				}
			}
		}
		
		return sparql.toString();
	}

	private String generateSparqlTypeClause(Node curr, String tab) throws Exception  {
		String retval = "";
		// Generates SPARQL to constrain the type of this node if
		// There is no edge that constrains it's type OR
		// the edge(s) that constrain it don't actually include it (they're all
		// super classes, so not enough constraint)
		
		ArrayList<String> constrainedTypes = this.getConnectedRange(curr);
		
		if(constrainedTypes.size() == 0 || !constrainedTypes.contains(curr.getFullUriName() )){
			// constrain to exactly the this type since there are no sub-types
			if(curr.getSubClassNames().size() == 0){
				retval += tab + curr.getSparqlID() + " a " + this.getPrefixedUri(curr.getFullUriName()) + " .\n";
			}
			else{
				retval += tab + curr.getSparqlID() + " a " + curr.getSparqlID() + "_type .\n";
				retval += tab + curr.getSparqlID() +  "_type " + " rdfs:subClassOf* " + this.getPrefixedUri(curr.getFullUriName()) + ".\n";
			}
		}
		
		return retval;
	}

	public void expandOptionalSubgraphs() throws Exception  {
		// Find nodes with only optional returns
		// and add incoming optional nodeItem so that entire snode is optional
		// then move the optional nodeItem outward until some non-optional return is found
		// this way the "whole chain" becomes optional.
		// Leave original optionals in place
		
		// For nodes with only one non-optional connection, and optional properties
		// make the node connection optional too
		for (Node snode : this.nodes) {
			
			
			// count optional and non-optional returns properties
			int optRet = 0;
			int nonOptRet = snode.getIsReturned() ? 1 : 0;
			for (PropertyItem prop :  snode.getReturnedPropertyItems()) {
				if (prop.getIsOptional()) {
					optRet += 1;
				} else {
					nonOptRet += 1;
				}
			}
			
			// if all returned props are optional
			if (optRet > 0 && nonOptRet == 0) {		
				ArrayList<Node> connectedSnodes = this.getAllConnectedNodes(snode);
				
				// if there's only one snode connected
				if (connectedSnodes.size() == 1) {
					Node otherSnode = connectedSnodes.get(0);
					ArrayList<NodeItem> nodeItems = this.getNodeItemsBetween(snode, otherSnode);
					
					// if it's only connected once between snode and otherSnode 
					// and connection is non-optional
					// then make it optional
					if (nodeItems.size() == 1) {
						NodeItem nodeItem = nodeItems.get(0);						
						
						// make the nodeItem optional inward
						if (snode.ownsNodeItem(nodeItem) && nodeItem.getSNodeOptional(otherSnode) == NodeItem.OPTIONAL_FALSE) {
							nodeItem.setSNodeOptional(otherSnode, NodeItem.OPTIONAL_REVERSE);
						} 
						if (otherSnode.ownsNodeItem(nodeItem) && nodeItem.getSNodeOptional(snode) == NodeItem.OPTIONAL_FALSE) {
							nodeItem.setSNodeOptional(snode, NodeItem.OPTIONAL_TRUE);
						}
					}
				}
			}
		}
		
		// now move optional nodeItems as far away from subgraph leafs as possible
		boolean changedFlag = true;
		while (changedFlag) {
			changedFlag = false;
			
			// loop through all snodes
			for (Node snode : this.nodes) {
				// count non-optional returns and optional properties
				int nonOptReturnCount = snode.getIsReturned() ? 1 : 0;
				int optPropCount = 0;
				for (PropertyItem pItem : snode.getReturnedPropertyItems()) {
					if (! pItem.getIsOptional()) {
						nonOptReturnCount++;
					} else if (pItem.getIsReturned()) {
						optPropCount++;
					}
				}
				
				// sort all connecting node items by their optional status: none, in, out
				ArrayList<NodeItem> normItems = new ArrayList<NodeItem>();
				ArrayList<Node>     normItems1 = new ArrayList<Node>();
				ArrayList<NodeItem> optOutItems = new ArrayList<NodeItem>();
				ArrayList<Node>     optOutItems1 = new ArrayList<Node>();
				ArrayList<NodeItem> optInItems= new ArrayList<NodeItem>();
				ArrayList<Node>     optInItems1 = new ArrayList<Node>();
				
				// outgoing nodes
				ArrayList<NodeItem> nItems = snode.getNodeItemList();
				for (NodeItem nItem : nItems) {
					if (nItem.getConnected()) {	
						for (Node target : nItem.getNodeList()) {
							int opt = nItem.getSNodeOptional(target);
						
							if (opt == NodeItem.OPTIONAL_FALSE) {
								normItems.add(nItem);
								normItems1.add(target);
								
							} else if (opt == NodeItem.OPTIONAL_TRUE) {
								optOutItems.add(nItem);
								optOutItems1.add(target);
								
							} else { // OPTIONAL_REVERSE
								optInItems.add(nItem);
								optInItems1.add(target);
							}
						}
					}
				}
				
				// incoming nodes
				for (NodeItem nItem : this.getConnectingNodeItems(snode)) {
					
					int opt = nItem.getSNodeOptional(snode);
					
					if (opt == NodeItem.OPTIONAL_FALSE) {
						normItems.add(nItem);
						normItems1.add(snode);
	
					} else if (opt == NodeItem.OPTIONAL_REVERSE) {
						optOutItems.add(nItem);
						optOutItems1.add(snode);
							
					} else {// OPTIONAL_TRUE
						optInItems.add(nItem);
						optInItems1.add(snode);
					}
					
				}
				
				// if nothing is returned AND
				//  one normal connection AND
				//  >=1 optional outward connections AND
				// no optional in connections AND
				if (nonOptReturnCount == 0 && normItems.size() == 1 && optOutItems.size() >= 1 && optInItems.size() == 0) {
				
					// set the single normal nodeItem to incoming optional
					NodeItem nItem = normItems.get(0);
					Node target = normItems1.get(0);
					
					if (target != snode) {
						nItem.setSNodeOptional(target,  NodeItem.OPTIONAL_REVERSE);
					} else {
						nItem.setSNodeOptional(target, NodeItem.OPTIONAL_TRUE);
					}

					// if there is only one outgoing optional, and no optional props here, 
					// then outgoing optional can be set to non-optional for performance
					if (optOutItems.size() == 1 && optPropCount == 0) {
						NodeItem oItem = optOutItems.get(0);
						Node oTarget = optOutItems1.get(0);
						oItem.setSNodeOptional(oTarget, NodeItem.OPTIONAL_FALSE);
					}
					 
					changedFlag = true;
				}
			}
		}
	}
	
	private ArrayList<Node> getOrderedNodeList()  {
		ArrayList<Node> ret = new ArrayList<Node>();
		
		ArrayList<Node> headList = this.getHeadNodes();
		
		for (Node n : headList) {
			ret.add(n);
			ret.addAll(this.getSubNodes(n));
		}
		
		ArrayList<Node> ret2 = new ArrayList<Node>();
		Hashtable hash = new Hashtable();
		
		// remove duplicates from ret
		for (Node n : ret) {
			if (hash.get(n.getSparqlID()) == null) {
				ret2.add(n);
				hash.put(n.getSparqlID(), 1);
			}
		}
		
		return ret2;
	}
	
	public void pruneAllUnused () {
		this.pruneAllUnused(false);
	}

	public void pruneAllUnused (boolean instanceOnly) {
		// prune all unused subgraphs
		ArrayList<Node> pruned = new ArrayList<Node>();
		boolean prunedSomething = true;
		
		// continue until every node has been pruned
		while (prunedSomething) {
			// list is different each time, so start over to find first unpruned node
			prunedSomething = false;
			for (Node node : this.nodes) {
				if (!pruned.contains(node)) {
					pruned.add(node);
					this.pruneUnusedSubGraph(node, instanceOnly);
					prunedSomething = true;
					break;   // go back to "while" since this.SNodeList is now changed
				}
			}
		} 
	}
	
	public boolean pruneUnusedSubGraph (Node node, boolean instanceOnly) {
		
		if (! node.isUsed(instanceOnly)) {
			ArrayList<Node> subNodes = this.getAllConnectedNodes(node);
			ArrayList<ArrayList<Node>> subGraphs = new ArrayList<ArrayList<Node>>();
			ArrayList<Integer> needSubTree = new ArrayList<Integer>();
			int needSubTreeCount = 0;
			
			ArrayList<Node> stopList = new ArrayList<Node>();
			stopList.add(node);
			
			// build a subGraph for every connection
			for (int i = 0; i < subNodes.size(); i++) {
				subGraphs.add(this.getSubGraph(subNodes.get(i), stopList));
				needSubTree.add(0);
				
				for (int j=0; j < subGraphs.get(i).size(); j++) {
					Node n = subGraphs.get(i).get(j);
					
					if (n.isUsed(instanceOnly))  {
						needSubTree.set(i, 1);
						needSubTreeCount += 1;
						break;
					}
				}
				if (needSubTreeCount > 1) break;
			}
			
			// if only one subGraph has nodes that are constrained or returned
			if (needSubTreeCount < 2) {
				
				// delete any subGraph with no returned or constrained nodes
				for (int i=0; i < subGraphs.size(); i++) {
					if (needSubTree.get(i) == 0) {
						for (int j=0; j < subGraphs.get(i).size(); j++) {
							Node n = subGraphs.get(i).get(j);
							this.deleteNode(n, false);
						}
					}
				}
				
				// recursively walk up the 'needed' subtree
				// pruning off any unUsed nodes and subGraphs
				ArrayList<Node> connList = this.getAllConnectedNodes(node);
				this.deleteNode(node, false);
				for (int i=0; i < connList.size(); i++) {
					this.pruneUnusedSubGraph(connList.get(i), instanceOnly);
				}
				
				return true;
			}
		}
		return false;
	}
	
	public void deleteNode (Node nd, boolean recurse) {
		ArrayList<String> sparqlIDsToRemove = new ArrayList<String>();
		ArrayList<Node> nodesToRemove = new ArrayList<Node>();
		
		// add the requested node
		nodesToRemove.add(nd);
		
		// if appropriate, get the children recursively.
		if (recurse) {
			ArrayList<Node> tempVal = this.getSubNodes(nd);
			nodesToRemove.addAll(tempVal);
		} else {
			// do nothing extra at all.
		}
		
		for (int j=0; j < nodesToRemove.size(); j++) {
			ArrayList<String> k = nodesToRemove.get(j).getSparqlIDList();
			sparqlIDsToRemove.addAll(k);
			// replaces tagging and removeTaggedNodes
			this.removeNode(nodesToRemove.get(j));
		}
		
		// free sparqlIDs
		for (int i = 0; i < sparqlIDsToRemove.size(); i++) {
			this.freeSparqlID(sparqlIDsToRemove.get(i));
		}
	}
	
	private void removeNode(Node node) {
		// replaces removeTaggedNodes:  only removes one specific node
		
		// remove the current sNode from all links.
		for (Node k : this.nodes) {
			k.removeFromNodeList(node);
		}
		
		// remove the sNode from the nodeGroup
		this.nodes.remove(node);
	}
	
	private ArrayList<Node> getSubGraph(Node startNode, ArrayList<Node> stopList) {
		ArrayList<Node> ret = new ArrayList<Node>();
		
		ret.add(startNode);
		ArrayList<Node> conn = this.getAllConnectedNodes(startNode);
		
		for (Node n : conn) {
			if (! stopList.contains(n) && ! ret.contains(n)) {
				ret.addAll(this.getSubGraph(n, ret));
			}
		}
		return ret;
	}
	
	public Node addPath(OntologyPath path, Node anchorNode, OntologyInfo oInfo ) throws Exception  {
		return this.addPath(path, anchorNode, oInfo, false, false);
	}
	
	public Node addPath(OntologyPath path, Node anchorNode, OntologyInfo oInfo, Boolean reverseFlag) throws Exception  {
		return this.addPath(path, anchorNode, oInfo, reverseFlag, false);
	}

	public Node addPath(OntologyPath path, Node anchorNode, OntologyInfo oInfo, Boolean reverseFlag, Boolean optionalFlag) throws Exception  {
		// Adds a path to the canvas.
		// path start class is the new one
		// path end class already exists
		// return the node corresponding to the path's startClass. (i.e. the one
		// the user is adding.)
		
		// reverseFlag:  in diabolic case where path is one triple that starts and ends on same class
		//               if reverseFlag, then connect
		
		// add the first class in the path
		Node retNode = this.addNode(path.getStartClassName(), oInfo);
		Node lastNode = retNode;
		Node node0;
		Node node1;
		int pathLen = path.getLength();
		// loop through path but not the last one
		for (int i = 0; i < pathLen - 1; i++) {
			String class0Uri = path.getClass0Name(i);
			String attUri = path.getAttributeName(i);
			String class1Uri = path.getClass1Name(i);

			// if this hop in path is  lastAdded--hasX-->class1
			if (class0Uri.equals(lastNode.getUri())) {
				node1 = this.returnBelmontSemanticNode(class1Uri, oInfo);
				this.addOneNode(node1, lastNode, null, attUri);
				lastNode = node1;
				
				if (optionalFlag) {
					throw new Exception("Internal error in belmont.js:AddPath(): SparqlGraph is not smart enough\nto add an optional path with links pointing away from the new node.\nAdding path without optional flag.");
					//optionalFlag = false;
				}
			// else this hop in path is class0--hasX-->lastAdded
			} else {
				node0 = this.returnBelmontSemanticNode(class0Uri, oInfo);
				this.addOneNode(node0, lastNode, attUri, null);
				lastNode = node0;
			}
		}

		// link the last two nodes, which by now already exist
		String class0Uri = path.getClass0Name(pathLen - 1);
		String class1Uri = path.getClass1Name(pathLen - 1);
		String attUri = path.getAttributeName(pathLen - 1);

		// link diabolical case from anchor node to last node in path
		if (class0Uri.equals(class1Uri) && reverseFlag ) {
			int opt = optionalFlag ? NodeItem.OPTIONAL_REVERSE : NodeItem.OPTIONAL_FALSE;
			anchorNode.setConnection(lastNode, attUri, opt);
			
		// normal link from last node to anchor node
		} else if (anchorNode.getUri().equals(class1Uri)) {
			int opt = optionalFlag ? NodeItem.OPTIONAL_REVERSE : NodeItem.OPTIONAL_FALSE;
			lastNode.setConnection(anchorNode, attUri, opt);
			
		// normal link from anchor node to last node
		} else {
			int opt = optionalFlag ? NodeItem.OPTIONAL_TRUE : NodeItem.OPTIONAL_FALSE;
			NodeItem nodeItem = anchorNode.setConnection(lastNode, attUri, opt);
		}
		return retNode;

	}
	
	public Node returnBelmontSemanticNode(String classUri, OntologyInfo oInfo) {
		// return a belmont semantic node represented by the class passed from
		// oInfo.
		// PAUL NOTE: this used to be in graphGlue.js
		// But there is no value in keeping oInfo and belmont separate, and
		// combining is elegant.
		OntologyClass oClass = oInfo.getClass(classUri);
		ArrayList<PropertyItem> belprops = new ArrayList<PropertyItem>();
		ArrayList<NodeItem> belnodes = new ArrayList<NodeItem>();

		// set the value for the node name:
		String nome = oClass.getNameString(true);
		String fullNome = oClass.getNameString(false);

		ArrayList<OntologyProperty> props = oInfo.getInheritedProperties(oClass);

		// get a list of the properties not repesenting other nodes.
		for (int i = 0; i < props.size(); i++) {
			String propNameLocal = props.get(i).getName().getLocalName();
			String propNameFull = props.get(i).getName().getFullName();
			String propRangeNameLocal = props.get(i).getRange().getLocalName();
			String propRangeNameFull = props.get(i).getRange().getFullName();

			// is the range a class ?
			if (oInfo.containsClass(propRangeNameFull)) {
				NodeItem p = new NodeItem(propNameLocal, propRangeNameLocal, propRangeNameFull);
				belnodes.add(p);

			}
			// range is string, int, etc.
			else {

				// create a new belmont property object and add it to the list.
				PropertyItem p = new PropertyItem(propNameLocal, propRangeNameLocal, propRangeNameFull, propNameFull);
				belprops.add(p);
			}
		}

		return new Node(nome, belprops, belnodes, fullNome, oInfo.getSubclassNames(classUri), this);
	}
	
	public HashMap<String, String> getSparqlNameHash() {
		return sparqlNameHash;
	}

	/**
	 * Adds one node without making any connections
	 * @param classUri
	 * @param oInfo
	 * @return Node
	 * @throws Exception 
	 * @ 
	 */
	public Node addNode(String classUri, OntologyInfo oInfo) throws Exception  {
		Node node = this.returnBelmontSemanticNode(classUri, oInfo);
		this.addOneNode(node, null, null, null);
		return node;
	}
	
	public void setSparqlConnection(SparqlConnection sparqlConn) {
		this.conn = sparqlConn;
	}
	
	public int getNodeCount() {
		return this.nodes.size();
	}
	
	private ArrayList<String> getArrayOfURINames() {
		ArrayList<String> retval = new ArrayList<String>();
		int t = this.nodes.size();
		for (int l = 0; l < t; l++) {
			// output the name
			retval.add(this.nodes.get(l).getUri());
			// alert(this.SNodeList[l].getURI());
		}
		return retval;

	}
	
	/**
	 * Set a property item to be returned, giving it a SparqlID if needed
	 * @param pItem
	 * @param val
	 * @return the sparqlId
	 */
	public String setIsReturned(PropertyItem pItem, boolean val) {
		String ret = null;
		pItem.setIsReturned(val);
		if (val && pItem.getSparqlID().isEmpty()) {
			ret = this.changeSparqlID(pItem, pItem.getKeyName());
		}
		return  ret;
	}
	
	/**
	 * Set a node to be returned, giving it a SparqlID if needed
	 * @param pItem
	 * @param val
	 * @return the sparqlId
	 */
	public String setIsReturned(Node node, boolean val) {
		String ret = null;
		node.setIsReturned(val);
		if (val && node.getSparqlID().isEmpty()) {
			ret = this.changeSparqlID(node, node.getUri(true));
		}
		return  ret;
	}
	
	public String changeSparqlID(PropertyItem obj, String requestID) {
		// API call for any object with get/setSparqlID:
		// set an object's sparqlID, making sure it is legal, unique, nameHash,
		// etc...
		// return the new id, which may be slightly different than the requested
		// id.

		this.freeSparqlID(obj.getSparqlID());
		String newID = BelmontUtil.generateSparqlID(requestID, this.sparqlNameHash);
		this.reserveSparqlID(newID);
		obj.setSparqlID(newID);
		return newID;
	}
	
	public String changeSparqlID(Node obj, String requestID) {
		// API call for any object with get/setSparqlID:
		// set an object's sparqlID, making sure it is legal, unique, nameHash,
		// etc...
		// return the new id, which may be slightly different than the requested
		// id.

		this.freeSparqlID(obj.getSparqlID());
		String newID = BelmontUtil.generateSparqlID(requestID, this.sparqlNameHash);
		this.reserveSparqlID(newID);
		obj.setSparqlID(newID);
		return newID;
	}

	public Node addClassFirstPath(String classURI, OntologyInfo oInfo, String domain, Boolean optionalFlag) throws Exception  {
		// attach a classURI using the first path found.
		// Error if less than one path is found.
		// return the new node
		// return null if there are no paths

		// get first path from classURI to this nodeGroup
		ArrayList<OntologyPath> paths = oInfo.findAllPaths(classURI, this.getArrayOfURINames(), domain);
		if (paths.size() == 0) {
			return null;
		}
		OntologyPath path = paths.get(0);
		
		// get first node matching anchor of first path
		ArrayList<Node> nlist = this.getNodesByURI(path.getAnchorClassName());
		
		// add sNode
		Node sNode = this.addPath(path, nlist.get(0), oInfo, false, optionalFlag);

		return sNode;
	}
	
	public Node getOrAddNode(String classURI, OntologyInfo oInfo, String domain) throws Exception  {
		return this.getOrAddNode(classURI, oInfo, domain, false, false);
	}
	
	public Node getOrAddNode(String classURI, OntologyInfo oInfo, String domain, Boolean superclassFlag) throws Exception  {
		return this.getOrAddNode(classURI, oInfo, domain, superclassFlag, false);
	}

	public Node getOrAddNode(String classURI, OntologyInfo oInfo, String domain, Boolean superclassFlag, Boolean optionalFlag ) throws Exception  {
		// return first (randomly selected) node with this URI
		// if none exist then create one and add it using the shortest path (see addClassFirstPath)
		// if superclassFlag, then any subclass of classURI "counts"
		// if optOptionalFlag: ONLY if node is added, change first nodeItem connection in path's isOptional to true
		
		// if gNodeGroup is empty: simple add
		Node sNode;
		
		if (this.getNodeCount() == 0) {
			sNode = this.addNode(classURI, oInfo);
			
		} else {
			// if node already exists, return first one
			ArrayList<Node> sNodes = new ArrayList<Node>(); 
			
			// if superclassFlag, then any subclass of classURI "counts"
			if (superclassFlag) {
				sNodes = this.getNodesBySuperclassURI(classURI, oInfo);
			// otherwise find nodes with exact classURI
			} else {
				sNodes = this.getNodesByURI(classURI);
			}
			
			if (sNodes.size() > 0) {
				sNode = sNodes.get(0);
			} else {
				sNode = this.addClassFirstPath(classURI, oInfo, domain, optionalFlag);
			}
		}
		return sNode;
	}
	
	private Node getNodeItemParentSNode(NodeItem nItem) {
		for (Node n : this.nodes) {
			if (n.getNodeItemList().contains(nItem)) {
				return n;
			}
		}
		return null;
	}
	
	private ArrayList<Node> getAllConnectedNodes(Node node) {
		ArrayList<Node> ret = new ArrayList<Node>();
		ret.addAll(node.getConnectedNodes());
		ret.addAll(this.getConnectingNodes(node));
		return ret;
	}
	
	private ArrayList<NodeItem> getNodeItemsBetween(Node sNode1, Node sNode2) {
		// return a list of node items between the two nodes
		// Ahead of the curve: supports multiple links between snodes
		ArrayList<NodeItem> ret = new ArrayList<NodeItem>();
		
		for (NodeItem i : sNode1.getNodeItemList()) {
			if (i.getNodeList().contains(sNode2)) {
				ret.add(i);
			}
		}
		
		for (NodeItem i : sNode2.getNodeItemList()) {

			if (i.getNodeList().contains(sNode1)) {
				ret.add(i);
			}
		}
		
		return ret;
	}
	
	private ArrayList<Node> getConnectingNodes(Node node) {
		ArrayList<Node> ret = new ArrayList<Node>();
		for (Node n : this.nodes) {
			if (n.getConnectingNodeItems(node).size() > 0 ) {
				ret.add(n);
			}
		}
		return ret;
	}
	
	private ArrayList<NodeItem> getConnectingNodeItems(Node sNode) {
		// get any nodeItem in the nodeGroup that points to sNode
		ArrayList<NodeItem> ret = new ArrayList<NodeItem>();
		for (Node n : this.nodes) {
			for (NodeItem nItem : n.getConnectingNodeItems(sNode) ) {
				ret.add(nItem);
			}
		}
		return ret;
	}
	
	private ArrayList<NodeItem> getAllConnectedNodeItems (Node sNode) {
		ArrayList<NodeItem> ret = new ArrayList<NodeItem>();
		
		// SNode knows who it points too
		ret.addAll(sNode.getNodeItemList());
		
		// nodegroup knows which nodes point to startSNode
		ret.addAll(this.getConnectingNodeItems(sNode));

		return ret;
	}
	
	public ArrayList<NodeItem> getAllConnectedConnectedNodeItems (Node sNode) {
		// get the connectedNodeItems that are actually in use
		ArrayList<NodeItem> ret = new ArrayList<NodeItem>();
		ArrayList<NodeItem> temp = this.getAllConnectedNodeItems(sNode);
		for (NodeItem nItem : temp) {
			if (nItem.getConnected()) {
				ret.add(nItem);
			}
		}
		return ret;
	}
	
	private ArrayList<Node> getSubNodes(Node topNode) {
		ArrayList<Node> subNodes = new ArrayList<Node>();
		
		ArrayList<Node> connectedNodes = topNode.getConnectedNodes();
		
		subNodes.addAll(connectedNodes);
		
		for (Node n : connectedNodes) {
			ArrayList<Node> innerSubNodes = this.getSubNodes(n);
			subNodes.addAll(innerSubNodes);
		}
		
		return subNodes;
	}
	
	private ArrayList<Node> getHeadNodes()  {
		ArrayList<Node> ret = new ArrayList<Node>();
		
		for (Node n : nodes) {
			int connCount = 0;
			for (Node o : nodes) {
				if (o.checkConnectedTo(n)) {
					++connCount;
					break;
				}
			}
			
			if (connCount == 0) {
				ret.add(n);
			}
		}
		
		if (!nodes.isEmpty() && ret.isEmpty()) {
			ret.add(nodes.get(0));
			// Danger in belmont.js getOrderedNodeList(): No head nodes found.  Graph is totally circular.
		}
		
		return ret;
	}
	
	private Node getNextHeadNode(ArrayList<Node> skipNodes) throws Exception  {
		if (skipNodes.size() == this.nodes.size()) {
			return null;
		}
		
		HashMap<String,Integer> optHash = this.calcOptionalHash(skipNodes);
		HashMap<String,Integer> linkHash = this.calcIncomingLinkHash(skipNodes);
		
		String retID = null;
		int minLinks = 99;
		
		// both hashes have same keys: loop through valid snode SparqlID's
		for (String id : optHash.keySet()) {
			// find nodes that are not optional
			if (optHash.get(id) == 0) {
				// choose node with lowest number of incoming links
				if (retID == null || linkHash.get(id) < minLinks) {
					retID = id;
					minLinks = linkHash.get(id);
					// be efficient
					if (minLinks == 0) { break; }
				}
			}
		}
		// throw an error if no nodes have optHash == 0
		if (retID == null) {
			throw new Exception("Internal error in NodeGroup.getHeadNextHeadNode(): No head nodes found. Probable cause: no non-optional semantic nodes.");
		}
		
		return this.getNodeBySparqlID(retID);
	}
	
	private HashMap<String, Integer> calcIncomingLinkHash (ArrayList<Node> skipNodes) {
		// so linkHash[snode.getSparqlID()] == count of incoming nodeItem links
		
		HashMap<String, Integer> linkHash = new HashMap<String, Integer>();
		
		// initialize hash
		for (Node snode : this.nodes) {
			if (! skipNodes.contains(snode)) {
				linkHash.put(snode.getSparqlID(), 0);
			}
		}
		
		// loop through all snodes
		for (Node snode : this.nodes) {
			
			if (! skipNodes.contains(snode)) {
				
				// loop through all nodeItems
				for (NodeItem nodeItem : snode.getNodeItemList()) {
					
					for (Node c : nodeItem.getNodeList()) {
						// increment hash[sparqlID] for each incoming link
						Integer val = linkHash.get(c.getSparqlID());
						linkHash.put(c.getSparqlID(), val + 1);
					}
				}
			}
		}
		return linkHash;
	}
	
	private HashMap<String, Integer>  calcOptionalHash(ArrayList<Node> skipNodes) throws Exception  {
		
		// ---- set optHash ----
		// so optHash[snode.getSparqlID()] == count of nodeItems indicating this node is optional
		HashMap<String, Integer> optHash = new HashMap<String, Integer>();

		// initialize optHash
		for (Node snode : this.nodes) {

			if (! skipNodes.contains(snode)) {
				optHash.put(snode.getSparqlID(), 0);
			}
		}
		
		// loop through all snodes
		for (Node snode : this.nodes) {
			
			if (! skipNodes.contains(snode)) {
				
				// loop through all nodeItems
				for (NodeItem nodeItem : snode.getNodeItemList()) {
					
					// loop through all connectedSNodes
					for (Node targetSNode : nodeItem.getNodeList()) {
						
						// if found an optional nodeItem
						int opt = nodeItem.getSNodeOptional(targetSNode);
						
						ArrayList<Node> subGraph = new ArrayList<Node>();
						
						// get subGraph(s) on the optional side of the nodeItem
						if (opt == NodeItem.OPTIONAL_TRUE) {
							ArrayList<Node> stopList = new ArrayList<Node>();
							stopList.add(snode);
							subGraph.addAll(this.getSubGraph(targetSNode, stopList));
							
						} else if (opt == NodeItem.OPTIONAL_REVERSE) {
							ArrayList<Node> stopList = new ArrayList<Node>();
							stopList.add(targetSNode);
							subGraph.addAll(this.getSubGraph(snode, stopList));
						}
							
						// increment every node on the optional side of the nodeItem
						for (Node k : subGraph) {
							int val = optHash.get(k.getSparqlID());
							optHash.put(k.getSparqlID(), val);
						}	
					}
				}
			}
		}
		
		return optHash;
	}
	
	private ArrayList<String> getConnectedRange(Node node) throws Exception  {
		ArrayList<String> retval = new ArrayList<String>();
		
		
		ArrayList<NodeItem> nodeItems = this.getConnectingNodeItems(node);
		for (NodeItem ni : nodeItems) {
			if (ni.getSNodeOptional(node) != NodeItem.OPTIONAL_REVERSE) {
				String uriValueType = ni.getUriValueType();
				if (!retval.contains(uriValueType)) {
					retval.add(uriValueType);
				}
			}
		}
		
		return retval;
	}
	
	/*
	 * PEC TODO: some of the following oInfo parameters are optional (empty oInfo works fine?)
	 *           and some are not.  It is confusing.  Can they be renamed or commented.
	 */
	public String generateSparqlDelete(OntologyInfo oInfo) throws Exception {
		return this.generateSparqlDelete(null, oInfo);
	}
	
	public String generateSparqlDelete(String post, OntologyInfo oInfo) throws Exception {
		this.buildPrefixHash();
		
		StringBuilder retval = new StringBuilder();
		
		String primaryBody = this.getDeletionLeader(post, oInfo);
		if(primaryBody == null || primaryBody.isEmpty() || primaryBody == ""){ throw new NoValidSparqlException("nothing given to delete.");}
		
		String whereBody = this.getDeletionWhereBody(post, oInfo);
		
		retval.append(this.generateSparqlPrefix() + "\nDELETE { \n" + primaryBody + "}") ;
		
		retval.append(this.generateSparqlFromClause(""));
		
		if(whereBody.length() != 0){	// there might be no where clause... 
			retval.append("\nWHERE {\n" + whereBody + "}\n");
		}
			
		return retval.toString();
	}

	public String getDeletionLeader(String post, OntologyInfo oInfo) throws Exception {
		
		StringBuilder retval = new StringBuilder();
		
		for(Node n : this.nodes){
			// get the node's deletion info.... this includes the properties, nodeitems and (potentially) the node itself.
			
			if( n.getDeletionMode() != NodeDeletionTypes.NO_DELETE){
				// we have something to do...
				retval.append(generateNodeDeletionSparql(n, false));
			}
			// check the properties.
			for( PropertyItem pi : n.getPropertyItems() ){
				if(pi.getIsMarkedForDeletion()){
					// check for a property that is actually going to be deleted. 
					retval.append("   " + n.sparqlID + " " +  this.getPrefixedUri( pi.getUriRelationship() ) + " " +  pi.sparqlID + " . \n"); 
				}
			}
			// check the nodeItems. 
			for( NodeItem ni : n.getNodeItemList() ) {
				ArrayList<Node> nic = ni.getSnodesWithDeletionFlagsEnabledOnThisNodeItem();
				for( Node connected : nic ){
					// write up the delete for this....
					retval.append("   " + n.sparqlID + " " + this.getPrefixedUri( ni.getUriConnectBy() ) + " " + connected.sparqlID +  " . \n");
				}
			}	
			// this should contain all the deletion info for the node itself.
		}
		// ship it out.
		return retval.toString();
	}
	
	private String generateNodeDeletionSparql(Node n, Boolean inWhereClause) throws Exception {
		String retval = "";
		String indent = "   ";
		NodeDeletionTypes delMode = n.getDeletionMode();
		
		if(delMode == NodeDeletionTypes.TYPE_INFO_ONLY){
			retval += indent + n.sparqlID + " rdf:type  " + n.sparqlID + "_type_info . \n";
		}
		else if(delMode == NodeDeletionTypes.FULL_DELETE){
			retval += indent + n.sparqlID + " rdf:type  " + n.sparqlID + "_type_info . \n";
			if(inWhereClause){ retval += " optional {"; } 
			retval += indent + n.sparqlID + " " + n.sparqlID + "_related_predicate_outgoing " + n.sparqlID + "_related_object_target . \n";
			retval += indent + n.sparqlID + "_related_subject " + n.sparqlID + "_related_predicate_incoming " + n.sparqlID + " . \n";
			if(inWhereClause){ retval += " } "; } 
		}
		else if(delMode == NodeDeletionTypes.LIMITED_TO_NODEGROUP){
			retval += indent + n.sparqlID + " rdf:type  " + n.sparqlID + "_type_info . \n";

			// get all incoming references to this particular node (in the current NodeGroup scope)
			// and schedule them for removal...
			for(Node ndIncomingCandidate : this.nodes){
				// get the node items and check the targets.
				for(NodeItem ni : ndIncomingCandidate.getConnectingNodeItems(n)){
					// set it so that the consequences of the decision are seen in the post-decision ND
					ni.setSnodeDeletionMarker(n, true);
					// generate the sparql snippet related to this deletion.
					retval += indent + ndIncomingCandidate.sparqlID + " " + this.getPrefixedUri(ni.getUriConnectBy()) + " " + n.sparqlID + " . \n";
				}
			}
			
			// generation of property deletion clauses is handled outside this method.
		}
		else if(delMode == NodeDeletionTypes.LIMITED_TO_MODEL){
			throw new Exception("NodeDeletionTypes.LIMITED_TO_MODEL is not currently implemented. sorry.");
		}
		else{
			// fail politely when the user/caller has no 
			throw new Exception("generateNodeDeletionSparql :: node with sparqlID (" + n.getSparqlID() + ") has an unimplemented DeletionMode (" + delMode.name() + ").");	
		}
		return retval;
	}

	public String getDeletionWhereBody(String post, OntologyInfo oInfo) throws Exception {
		StringBuilder retval = new StringBuilder();
		
		ArrayList<Node> doneNodes = new ArrayList<Node>();
		Node headNode = this.getNextHeadNode(doneNodes);
		while (headNode != null) {
			// for each node, get the subgraph clauses, including constraints.
			retval.append(this.generateSparqlSubgraphClauses(	AutoGeneratedQueryTypes.QUERY_DELETE_WHERE, headNode, null, null, null, doneNodes, "   "));
			headNode = this.getNextHeadNode(doneNodes);
		}
		
		return retval.toString();
	}
	
	
	public String generateSparqlInsert(OntologyInfo oInfo) throws Exception {
		return this.generateSparqlInsert(null, oInfo);
	}
	
	public String generateSparqlInsert(String post, OntologyInfo oInfo) throws Exception {
		this.buildPrefixHash();
		
		String retval = "";
		// get the primary insert body.
		String primaryBody = this.getInsertLeader(post, oInfo);
		
		// get the where clause body
		String whereBody = this.getInsertWhereBody(post, oInfo);
		
		retval =  this.generateSparqlPrefix() + " INSERT {\n" + primaryBody + "} WHERE {" + whereBody + "}\n";
		
		return retval;
	}
	

	public String getInsertLeader(String postfixSparqlIDs, OntologyInfo oInfo) throws Exception  {
		// this method creates the top section of the insert statements.
		// the single argument is used to post-fix the sparqlIDs, if required. 
		// this is used in the generation of bulk insertions. 
		this.buildPrefixHash();
		
		String retval = "";
		if(postfixSparqlIDs == null){ postfixSparqlIDs = "";}
		
		// loop through the nodes and get any values we may need. 
		for(Node curr : this.nodes){
			
			Boolean currIsEnum = oInfo.classIsEnumeration(curr.getFullUriName());
			Boolean currInstanceBlank = false;
			String currInstanceValue = curr.getInstanceValue();
			
			if(currInstanceValue == null || currInstanceValue == "" || currInstanceValue.isEmpty()){
				currInstanceBlank = true;
			}

			String sparqlID = curr.getSparqlID() + postfixSparqlIDs;
			// makes sure to indicate that this node was of its own type. it comes up.
		
			/**
			 * There is a subtlety here where one can get into trouble if a node has no instance value (the instance uri)
			 * this comes in two flavors:
			 * 1. the node referenced is an enumeration and we should drop it. can't go inventing new ones just because
			 * 2. basically make a blank node because we need those one on the path. this one is interesting because we need to makes sure
			 *    there is an in or out edge to our unnamed node, or else we are just making clutter. 
			 *    
			 *    Note: for now, we are going to make the clutter. 
			 */
			
			// only add this node if the current instance should be included. 
			if((!currIsEnum) || (currIsEnum && !currInstanceBlank)){
				retval += "\t" + sparqlID + " a " + this.getPrefixedUri(curr.getFullUriName()) + " . \n";
				
				// insert each property we know of. 
				for(PropertyItem prop : curr.getPropertyItems()){
					for(String inst : prop.getInstanceValues()){
						retval += "\t" + sparqlID + " " + this.getPrefixedUri(prop.getUriRelationship()) + " \"" + inst + "\"^^" + this.getPrefixedUri("http://www.w3.org/2001/XMLSchema#" + prop.getValueType()) + " .\n";  
					}
				}
				
				// insert a line for each node item
				for(NodeItem ni : curr.getNodeItemList()){
					for(Node currentConnection : ni.getNodeList()){
						retval += "\t" + sparqlID + " " + this.getPrefixedUri(ni.getUriConnectBy()) + " " + currentConnection.getSparqlID() + postfixSparqlIDs + " .\n";
					}
				}
			}
		}
		
		return retval;
	}
	
	public String getInsertWhereBody(String postfixSparqlIDs, OntologyInfo oInfo) throws Exception  {
		
		this.buildPrefixHash();
		StringBuilder sparql = new StringBuilder();
		
		if (postfixSparqlIDs == null) {
			postfixSparqlIDs = "";
		}
		
		for (Node node : this.nodes) {
			String sparqlId = node.getSparqlID() + postfixSparqlIDs;
			

			Boolean currIsEnum = oInfo.classIsEnumeration(node.getFullUriName());
			Boolean currInstanceBlank = false;
			String currInstanceValue = node.getInstanceValue();
			
			if(currInstanceValue == null || currInstanceValue == "" || currInstanceValue.isEmpty()){
				currInstanceBlank = true;
			}

			// node was specified
			if (!currInstanceBlank) {
				
				String nodeVal = node.getInstanceValue();
				
				if(!nodeVal.contains("#")){
					nodeVal = UriResolver.DEFAULT_URI_PREFIX + nodeVal;
				}
				
//				sparql.append("\tBIND (<").append(nodeVal).append("> AS ").append(sparqlId).append(").\n");
				sparql.append("\tBIND (").append(this.getPrefixedUri(nodeVal)).append(" AS ").append(sparqlId).append(").\n");
			}
			else if(currInstanceBlank && !currIsEnum){
				ArrayList<PropertyItem> constrainedProps = node.getConstrainedPropertyObjects();
				
				if (!constrainedProps.isEmpty()) {
					// node is constrained
					
					for (PropertyItem pi : constrainedProps) {
				//		sparql.append(" ").append(sparqlId).append(" <").append(pi.getUriRelationship())
				//			.append("> ").append(pi.getSparqlID()).append(". ").append(pi.getConstraints())
				//			.append(" .\n");
						sparql.append(" ").append(sparqlId).append(" ").append(this.getPrefixedUri(pi.getUriRelationship()))
								.append(" ").append(pi.getSparqlID()).append(". ").append(pi.getConstraints())
								.append(" .\n");
					}
				}
				
				else {
					// node not constrained, create new URI
					
					// create new instance
					// we have to be able to check if the Node has "instanceValue" set. if it does. we want to reuse that. if not, kill it.
					if (node.getInstanceValue() != null && !node.getInstanceValue().equals("") && !node.getInstanceValue().isEmpty()) {
						String nodeVal = node.getInstanceValue();
						if(!nodeVal.contains("#")){
							nodeVal = UriResolver.DEFAULT_URI_PREFIX + nodeVal;
						}
						
						sparql.append("\tBIND (iri(\"").append(this.getPrefixedUri(nodeVal))
							.append("\") AS ").append(sparqlId).append(").\n");
					}
					else {
						//sparql.append("\tBIND (iri(concat(\"" + UriResolver.DEFAULT_URI_PREFIX + "\", \"")
						//	.append(UUID.randomUUID().toString()).append("\")) AS ")
						//	.append(sparqlId).append(").\n");
						
						sparql.append("\tBIND (iri(concat(\"" + this.getPrefixedUri(UriResolver.DEFAULT_URI_PREFIX) + "\", \"")
							.append(UUID.randomUUID().toString()).append("\")) AS ")
							.append(sparqlId).append(").\n");
						
						
					}
				}
			}
			
		}
		
		return sparql.toString();
	}

	public JSONObject toJson()  {
		return this.toJson(null);
	}

	/**
	 * 
	 * @param mappedPropItems - null=don't deflate ;  non-null=deflate
	 * @return
	 * @
	 */
	@SuppressWarnings("unchecked")
	public JSONObject toJson(ArrayList<PropertyItem> mappedPropItems)  {
		JSONObject ret = new JSONObject();
		
		// get list in order such that linked nodes always preceed the node that
		// links to them
		ArrayList<Node> orig = this.getOrderedNodeList();
		ArrayList<Node> snList = new ArrayList<Node>();
		for (int i = orig.size()-1; i >=0; i--) {
			snList.add(orig.get(i));
		}
		
		ret.put("version", VERSION);
		ret.put("limit", this.limit);
		ret.put("offset", this.offset);
		
		// orderBy
		JSONArray orderBy = new JSONArray();
		for (int i=0; i < this.orderBy.size(); i++) {
			orderBy.add(this.orderBy.get(i).toJson());
		}
		ret.put("orderBy", orderBy);
		
		// sNodeList
		JSONArray sNodeList = new JSONArray();
		for (int i=0; i < snList.size(); i++) {
			sNodeList.add(snList.get(i).toJson(mappedPropItems));
		}
		ret.put("sNodeList", sNodeList);
		
		return ret;
	}
	
	public HashMap<String, RuntimeConstrainedObject> getConstrainedItems(){
		HashMap<String, RuntimeConstrainedObject> retval = new HashMap<String, RuntimeConstrainedObject>();
		
		// go through all of the nodegroup contents and send back the collection.
		for(Node curr : this.nodes){
			if(curr.getIsRuntimeConstrained()){ 
				// this one is constrained. add it to the list. 
				
				RuntimeConstrainedObject currConst = new RuntimeConstrainedObject((Returnable)curr, RuntimeConstrainedItems.SupportedTypes.NODE);
				retval.put(curr.sparqlID, currConst);
			}
			else{
				// do nothing.
			}
			
			// check the properties to make sure that we get them all. 
			for(PropertyItem pi : curr.getPropertyItems()){
				if(pi.getIsRuntimeConstrained()){
					RuntimeConstrainedObject currConst = new RuntimeConstrainedObject((Returnable)pi, RuntimeConstrainedItems.SupportedTypes.PROPERTYITEM);
					retval.put(pi.sparqlID, currConst);
				}
				else{
					// do nothing.
				}
			}
		}
		return retval;
	}
	
	public void inflateAndValidate(OntologyInfo oInfo) throws Exception  {
		if (oInfo.getNumberOfClasses() == 0 && this.getNodeList().size() > 0) {
			throw new Exception("Model contains no classes. Nodegroup can't be validated.");
		}
		
		for (Node n : this.getNodeList()) {
			n.inflateAndValidate(oInfo);
		}
	}
	
	public void validateAgainstModel(OntologyInfo oInfo) throws Exception  {
		if (oInfo.getNumberOfClasses() == 0 && this.getNodeList().size() > 0) {
			throw new Exception("Model contains no classes. Nodegroup can't be validated.");
		}
		
		for (Node n : this.getNodeList()) {
			n.validateAgainstModel(oInfo);
		}
	}
}
