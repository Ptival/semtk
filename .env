#!/bin/bash

#
#

# require that this file be sourced from the folder containing it (previously for Docker compose - possibly not needed now)
if [ ! -f ".env" ]; then
	echo ".env needs to be in the current working folder of the process that sourced it"
	exit 1
fi

# Helper functions
. ./.fun
os
hostip
sethostname

# Don't source this file twice.
if [ ! -z ${SOURCED_OSS_ENV+x} ]; then
    echo "Returning (already ran .env)"
	return
fi
export SOURCED_OSS_ENV=true

# Proxy settings [optional] - set if your network requires a proxy to connect to the Internet
export httpProxyHost=
export httpProxyPort=80
if [ -z "${httpProxyHost}" ]; then
	export http_proxy=""
else
	export http_proxy=http://${httpProxyHost}:${httpProxyPort}
fi
export httpsProxyHost=$httpProxyHost
export httpsProxyPort=$httpProxyPort
export https_proxy=$http_proxy
export no_proxy=${HOST_IP},localhost
export nonProxyHosts="${HOST_IP}|localhost"

## Volume map [optional] - Mapping of external to internal paths including the -v switch. Example $(pwd):/wd
export VOL_MAP="-v $(pwd):/wd -v $(pwd)/../../.m2:/root/.m2"

## RUN_OPTS [optional] - additional options to specify with the run comman. Example -e POSTGRES_DB=dbname
export RUN_OPTS="-e http_proxy=$http_proxy -e https_proxy=$https_proxy -e no_proxy=$no_proxy -e httpProxyHost=$httpProxyHost -e httpProxyPort=$httpProxyPort -e httpsProxyHost=$httpsProxyHost -e httpsProxyPort=$httpsProxyPort -e nonProxyHosts=$nonProxyHosts"

## JVM_OPTIONS [optional] values specified here will be passed to java processes
export JVM_OPTIONS="-Xmx20G -Xincgc"
export JVM_OPTIONS_LARGE_MEMORY="-Xmx50G -Xincgc"

## setting SSL_ENABLED=true (and populating 3 keystore settings) makes services accept HTTPS
export SSL_ENABLED=false
export SSL_KEY_STORE_TYPE=PKCS12
export SSL_KEY_STORE=
export SSL_KEY_STORE_PASSWORD=

export SERVER_ADDRESS=

## ports
export PORT_SPARQLDB=2420
export PORT_SPARQLGRAPH_WEB=8860
export PORT_SPARQL_QUERY_SERVICE=12050
export PORT_SPARQLGRAPH_STATUS_SERVICE=12051
export PORT_SPARQLGRAPH_RESULTS_SERVICE=12052
export PORT_DISPATCH_SERVICE=12053
export PORT_HIVE_SERVICE=12055
export PORT_NODEGROUPSTORE_SERVICE=12056
export PORT_ONTOLOGYINFO_SERVICE=12057
export PORT_NODEGROUPEXECUTION_SERVICE=12058
export PORT_NODEGROUP_SERVICE=12059
export PORT_UTILITY_SERVICE=12060

export PORT_INGESTION_SERVICE=12091
export PORT_ATHENA_SERVICE=12062
export PORT_EDCQUERYGEN_SERVICE=12054
export PORT_BINARYFILE_SERVICE=12064
export PORT_ARANGODB_SERVICE=12065
export PORT_FDCSAMPLE_SERVICE=12066
export PORT_FDCCACHE_SERVICE=12068

## dataset for jobs and EDC services
export SERVICES_DATASET_SERVER_URL=http://${HOST_IP}:${PORT_SPARQLDB}
export SERVICES_DATASET_ENDPOINT_TYPE=virtuoso
export SERVICES_DATASET_DOMAIN=http://
export SERVICES_DATASET=http://research.ge.com/semtk/services

## dataset for integration testing
export TESTGRAPH_SERVER_URL=${SERVICES_DATASET_SERVER_URL}
export TESTGRAPH_ENDPOINT_TYPE=${SERVICES_DATASET_ENDPOINT_TYPE}

## sparqldb service
export DATA_SPARQLDB=$(pwd)/sparqlDB/virtuoso
export PWD_SPARQLDB=dba

# protocol for calling the services
export SERVICE_PROTOCOL=http

## sparql query service
export SPARQLQUERY_SERVICE_HOST=${HOST_NAME}
export SPARQLQUERY_SERVICE_PROTOCOL=${SERVICE_PROTOCOL}
export SPARQLQUERY_SERVICE_ENDPOINT=/sparqlQueryService/query
export SPARQLQUERY_SERVICE_ENDPOINT_AUTH=/sparqlQueryService/queryAuth
# TODO credentials should be made specific to dataset server url
export SPARQLQUERY_SERVICE_USER=dba
export SPARQLQUERY_SERVICE_PWD=dba

export NEPTUNE_UPLOAD_S3_CLIENT_REGION=
export NEPTUNE_UPLOAD_S3_BUCKET_NAME=
export NEPTUNE_UPLOAD_S3_AWS_IAM_ROLE_ARN=

## status service
export STATUS_SERVICE_HOST=${HOST_NAME}
export STATUS_SERVICE_PROTOCOL=${SERVICE_PROTOCOL}
export statusJobMaxWaitMsec=300000
export statusLoggingEnabled=false
export statusApplicationLogName=StatusService

## results service
export RESULTS_SERVICE_HOST=${HOST_NAME}
export RESULTS_SERVICE_PROTOCOL=${SERVICE_PROTOCOL}
export RESULTS_SERVICE_MULTIPART_MAXFILESIZE=1000MB
export RESULTS_SERVICE_MULTIPART_MAXREQUESTSIZE=1000MB
export resultsCleanUpThreadsEnabled=YES
export resultsCleanUpThreadsFrequency=480
export resultsLoggingEnabled=false
export resultsApplicationLogName=ResultsService
export resultsBaseURL=${SERVICE_PROTOCOL}://${RESULTS_SERVICE_HOST}:${PORT_SPARQLGRAPH_RESULTS_SERVICE}
export resultsServiceURL=${SERVICE_PROTOCOL}://${RESULTS_SERVICE_HOST}:${PORT_SPARQLGRAPH_RESULTS_SERVICE}/results
export resultsFileLocation=/tmp/DISPATCH_RESULTS
export resultsSampleLines=100

## dispatch service
export DISPATCH_SERVICE_HOST=${HOST_NAME}
export DISPATCH_SERVICE_PROTOCOL=${SERVICE_PROTOCOL}
export LOCATION_ADDITIONAL_DISPATCHER_JARS=""
export DISPATCHER_CLASS_NAME=com.ge.research.semtk.sparqlX.asynchronousQuery.AsynchronousNodeGroupDispatcher

## hive service
export HIVE_SERVICE_HOST=${HOST_NAME}
export HIVE_SERVICE_PROTOCOL=${SERVICE_PROTOCOL}
export hiveUsername=hive
export hivePassword=password
export HIVE_LOGIN_TIMEOUT_SEC=60

## nodegroup store service
export NODEGROUPSTORE_SERVICE_HOST=${HOST_NAME}
export NODEGROUPSTORE_SERVICE_PROTOCOL=${SERVICE_PROTOCOL}
export NODEGROUPSTORE_SERVICE_MULTIPART_MAXFILESIZE=1000MB
export storeSparqlServerDataDataset=http://research.ge.com/knowledge/prefab/data
export storeSparqlServerModelDataset=http://research.ge.com/knowledge/prefab/model
export storeSparqlServerDomain=http://

## ontology info service
export ONTOLOGYINFO_SERVICE_HOST=${HOST_NAME}
export ONTOLOGYINFO_SERVICE_PROTOCOL=${SERVICE_PROTOCOL}
export oinfoLoggingEnabled=false
export oinfoApplicationLogName=OntologyInfoService

## nodegroup execution service
export NODEGROUPEXECUTION_SERVICE_HOST=${HOST_NAME}
export NODEGROUPEXECUTION_SERVICE_PROTOCOL=${SERVICE_PROTOCOL}
export nodeGroupExecutionLoggingEnabled=false
export nodeGroupExecutionApplicationLogName=NodeGroupExecutionService

## nodegroup service
export NODEGROUP_SERVICE_HOST=${HOST_NAME}
export NODEGROUP_SERVICE_PROTOCOL=${SERVICE_PROTOCOL}
export NODEGROUP_SERVICE_MULTIPART_MAXFILESIZE=1000MB

## ingestion service
export INGESTION_SERVICE_HOST=${HOST_NAME}
export INGESTION_SERVICE_PROTOCOL=${SERVICE_PROTOCOL}
export INGESTION_SERVICE_MULTIPART_MAXFILESIZE=1000MB
export ingestionBatchSize=16
export ingestionLoggingEnabled=false
export ingestionApplicationName=IngestionService

## fdc sample
export FDCSAMPLE_SERVICE_HOST=${HOST_NAME}

## logging service
export LOGGING_SERVICE_HOST=${HOST_NAME}
export LOGGING_SERVICE_PROTOCOL=${SERVICE_PROTOCOL}
export LOGGING_SERVICE_PORT=12092
export LOGGING_SERVICE_ENDPOINT=/Logging/usageLog

## athenaService
export ATHENA_SERVICE_HOST=${HOST_NAME}
export ATHENA_AWS_REGION_ID=us-east-1
export ATHENA_AWS_S3_OUTPUT_BUCKET=s3://bucket
export ATHENA_AWS_KEY=fake2391-23984-248
export ATHENA_AWS_CLIENT_EXECUTION_TIMEOUT=7000
export ATHENA_TEST_DATABASE=dbget

## arangoDbService
export ARANGODB_SERVICE_HOST=${HOST_NAME}
export ARANGODB_SERVICE_PROTOCOL=${SERVICE_PROTOCOL}
export ARANGODB_USER=user
export ARANGODB_PASSWORD=password
export ARANGODB_TEST_SERVER=
export ARANGODB_TEST_PORT=8529

## binaryFileService
export BINARYFILE_SERVICE_HOST=${HOST_NAME}

export BINARY_SHARED_DIRECTORY=/mnt/island/materials
export BINARY_HDFS_DOWNLOAD_SERVICE_PROTOCOL=http
export BINARY_HDFS_DOWNLOAD_SERVICE_HOST=server001.com
export BINARY_HDFS_DOWNLOAD_SERVICE_PORT=34152
export binaryLoggingEnabled=false
export binaryApplicationLogName=BinaryFileService

## hive
export HIVE_TEST_SERVER=
export HIVE_TEST_PORT=10000
export HIVE_TEST_DATABASE=
export HIVE_TEST_USERNAME=
export HIVE_TEST_PASSWORD=

## kairos
export KAIROS_TEST_SERVER=
export KAIROS_TEST_PORT=34156
export KAIROS_TEST_URL=http://server001.com:8080

export EDCQUERYGEN_SERVICE_HOST=${HOST_NAME}

## authorization

export AUTH_SETTINGS_FILE_PATH=NO_AUTH
export AUTH_LOG_PATH=/tmp/semtk_auth_log.txt
export AUTH_REFRESH_FREQ_SEC=300 
export AUTH_USERNAME_KEY=user_name
export AUTH_GROUP_KEY=group

## semtk-sparqlgraph-web
export INGEST_URL=${SERVICE_PROTOCOL}://${INGESTION_SERVICE_HOST}:${PORT_INGESTION_SERVICE}/ingestion/
export QUERY_URL=${SERVICE_PROTOCOL}://${SPARQLQUERY_SERVICE_HOST}:${PORT_SPARQL_QUERY_SERVICE}/sparqlQueryService/
export STATUS_URL=${SERVICE_PROTOCOL}://${STATUS_SERVICE_HOST}:${PORT_SPARQLGRAPH_STATUS_SERVICE}/status/
export RESULTS_URL=${SERVICE_PROTOCOL}://${RESULTS_SERVICE_HOST}:${PORT_SPARQLGRAPH_RESULTS_SERVICE}/results/
export DISPATCHER_URL=${SERVICE_PROTOCOL}://${DISPATCH_SERVICE_HOST}:${PORT_DISPATCH_SERVICE}/dispatcher/
export HIVE_URL=${SERVICE_PROTOCOL}://${HIVE_SERVICE_HOST}:${PORT_HIVE_SERVICE}/hiveService/
export NGSTORE_URL=${SERVICE_PROTOCOL}://${NODEGROUPSTORE_SERVICE_HOST}:${PORT_NODEGROUPSTORE_SERVICE}/nodeGroupStore/
export OINFO_URL=${SERVICE_PROTOCOL}://${ONTOLOGYINFO_SERVICE_HOST}:${PORT_ONTOLOGYINFO_SERVICE}/ontologyinfo/
export NGEXEC_URL=${SERVICE_PROTOCOL}://${NODEGROUPEXECUTION_SERVICE_HOST}:${PORT_NODEGROUPEXECUTION_SERVICE}/nodeGroupExecution/
export NG_URL=${SERVICE_PROTOCOL}://${NODEGROUP_SERVICE_HOST}:${PORT_NODEGROUP_SERVICE}/nodeGroup/
 
export SECURE_REST_CLIENTS=false

## repeats of the above, renamed for the Tomcat web html and js
# --------------- IMPORTANT ---------------
#           injected into javascript
export WEB_PROTOCOL=${SERVICE_PROTOCOL}
export WEB_INGESTION_HOST=${INGESTION_SERVICE_HOST}
export WEB_INGESTION_PORT=${PORT_INGESTION_SERVICE}
export WEB_SPARQL_QUERY_HOST=${SPARQLQUERY_SERVICE_HOST}
export WEB_SPARQL_QUERY_PORT=${PORT_SPARQL_QUERY_SERVICE}
export WEB_STATUS_HOST=${STATUS_SERVICE_HOST}
export WEB_STATUS_PORT=${PORT_SPARQLGRAPH_STATUS_SERVICE}
export WEB_RESULTS_HOST=${RESULTS_SERVICE_HOST}
export WEB_RESULTS_PORT=${PORT_SPARQLGRAPH_RESULTS_SERVICE}
export WEB_DISPATCH_HOST=${DISPATCH_SERVICE_HOST}
export WEB_DISPATCH_PORT=${PORT_DISPATCH_SERVICE}
export WEB_HIVE_HOST=${HIVE_SERVICE_HOST}
export WEB_HIVE_PORT=${PORT_HIVE_SERVICE}
export WEB_NODEGROUPSTORE_HOST=${NODEGROUPSTORE_SERVICE_HOST}
export WEB_NODEGROUPSTORE_PORT=${PORT_NODEGROUPSTORE_SERVICE}
export WEB_ONTOLOGYINFO_HOST=${ONTOLOGYINFO_SERVICE_HOST}
export WEB_ONTOLOGYINFO_PORT=${PORT_ONTOLOGYINFO_SERVICE}
export WEB_NODEGROUPEXECUTION_HOST=${NODEGROUPEXECUTION_SERVICE_HOST}
export WEB_NODEGROUPEXECUTION_PORT=${PORT_NODEGROUPEXECUTION_SERVICE}
export WEB_NODEGROUP_HOST=${NODEGROUP_SERVICE_HOST}
export WEB_NODEGROUP_PORT=${PORT_NODEGROUP_SERVICE}
export WEB_USER_ENDPOINT=/user

# wrap these values in single quotes
# there is no known way to include quotes in the text or html
export WEB_CUSTOM_BANNER_TEXT=none
export WEB_CUSTOM_STARTUP_DIALOG_TITLE=none
export WEB_CUSTOM_STARTUP_DIALOG_HTML=none
export WEB_CUSTOM_AUTO_RUN_DEMO_FLAG=true

# --------------- IMPORTANT ---------------


# apply any overrides to settings we just loaded
if [ -f DOT_SETTINGS ] && [ -f ENV_OVERRIDE ]; then
	echo Error: both the older DOT_SETTINGS and newer ENV_OVERRIDE are present.
	echo Remove one of them
	exit 1
elif [ -f DOT_SETTINGS ]; then
	echo Using deprecated DOT_SETTINGS.  Please rename to ENV_OVERRIDE.
	. ./DOT_SETTINGS
elif [ -f ENV_OVERRIDE ]; then
	. ./ENV_OVERRIDE
fi
